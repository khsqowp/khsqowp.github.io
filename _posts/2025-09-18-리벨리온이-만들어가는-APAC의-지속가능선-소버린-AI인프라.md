--- 
title: "AI 반도체 추론 시장의 미래: 리벨리온과 인텔의 전략"
date: 2025-09-18
excerpt: "AI 추론 시장에 특화된 리벨리온의 NPU 기술과 소버린 AI 전략, 그리고 인텔의 엔터프라이즈 AI를 위한 CPU/가속기 이원화 접근법을 분석합니다."
categories:
  - Archive
  - conference
  - DIC 2025
tags:
  - DIC 2025
  - conference
  - Archive
---

# AI 인프라의 미래: 리벨리온과 인텔의 전략

## 파트 1: 리벨리온(Rebellions)이 만들어가는 APAC의 지속가능한 소버린 AI 인프라

**발표자:** 정윤정, 리벨리온 CSO

### 서론: AI 추론 시장을 정조준하는 K-팹리스

리벨리온은 창업 5년 만에 기업가치 1조 원을 넘은 유니콘 기업으로, 아시아에서 가장 빠르게 성장하는 AI 반도체 팹리스(Fabless) 스타트업입니다. 250여 명의 인력 중 200명 이상이 엔지니어이며, SK, 삼성, KT, 아람코 등 국내외 거대 기업들의 전략적 투자를 유치하며 기술력과 시장성을 모두 인정받고 있습니다. 리벨리온의 목표는 명확합니다. NVIDIA가 장악한 AI '훈련(Training)' 시장이 아닌, 폭발적으로 성장하는 AI **'추론(Inference)'** 시장에서 세계 최고의 에너지 효율과 성능을 가진 반도체를 제공하는 것입니다.

### 전략: 왜 '추론' 시장인가?

AI 반도체 시장은 크게 모델을 개발하는 '훈련'과, 만들어진 모델을 서비스로 제공하는 '추론'으로 나뉩니다. 두 시장은 고객의 요구사항이 근본적으로 다릅니다.

*   **훈련 시장:** 모델 개발의 속도가 중요하므로, **최고의 연산 처리량(Throughput)**과 개발자 생태계가 강력한 **NVIDIA의 CUDA**가 절대적인 영향력을 가집니다. 리벨리온은 15년간 쌓아온 CUDA의 아성을 단기간에 넘기 어렵다고 판단합니다.
*   **추론 시장:** 최종 사용자의 서비스 경험과 사업의 수익성이 중요합니다. 따라서 고객은 **빠른 응답 속도(Low Latency)**와 **전력 효율(TCO, 총소유비용 절감)**을 최우선으로 고려합니다. 또한, 특정 서비스에 맞게 최적화하기 용이한 **오픈소스 소프트웨어 스택(Triton, vLLM 등)**을 선호하는 경향이 뚜렷합니다.

리벨리온은 바로 이 지점에서 기회를 찾았습니다. 추론 시장은 수익성을 고민하는 비즈니스 운영자들이 구매 결정권을 가지며, 이들은 CUDA가 아니더라도 더 빠르고 에너지 효율적인 대안이 있다면 기꺼이 선택할 용의가 있습니다. 리벨리온은 '추론' 하나에만 집중하여, 이 시장에서 가장 지속가능한 AI 서비스를 위한 반도체를 만들겠다는 미션을 가지고 있습니다.

### 기술: 선택과 집중을 통한 효율 극대화

리벨리온의 핵심 경쟁력은 '추론 연산에 최적화된 아키텍처'입니다. 범용성을 위해 다양한 기능을 지원하는 NVIDIA GPU와 달리, 리벨리온의 칩은 추론에 불필요한 기능을 과감히 제거하고 오직 추론 연산만을 위해 설계되었습니다. 그 결과, **동일 성능에서 2~3배 이상의 에너지 효율**을 달성합니다.

*   **ATOM (1세대 칩):** MLPerf 벤치마크 테스트에서 동급 NVIDIA 제품(L4) 대비 3~4배 빠른 처리 속도를 증명하며 기술력을 입증했습니다.
*   **REBEL (차세대 칩):** NVIDIA의 최신 칩(호퍼/블랙웰)과 경쟁하기 위해 개발된 제품으로, 리벨리온의 구조적 경쟁력을 그대로 계승했습니다.
*   **칩렛(Chiplet) 전략:** 리벨리온의 빠른 제품 개발 로드맵의 핵심입니다. 거대한 단일 칩(Monolithic)을 만드는 대신, 작은 기능 단위의 칩(칩렛)을 레고처럼 조합하여 다양한 목적의 제품을 신속하게 만드는 전략입니다. 이를 통해 I/O를 강화한 '리벨 아이오', 메모리를 확장한 '리벨 메모리', CPU를 통합한 '리벨 CPU' 등 고객 맞춤형 제품 라인업을 빠르게 확장할 계획입니다.
*   **기술적 성과:** 최근 공개된 '리벨 쿼드(REBEL QUAD)'는 세계 최초로 **4개의 칩렛**과 **최신 HBM3 메모리**를 동시에 적용하고 성공적으로 구동시킨 스타트업 제품으로, 글로벌 시장에서 큰 주목을 받았습니다.

### 시장 진출 전략: '소버린 AI'를 발판으로 글로벌로

리벨리온은 3단계 시장 진출 전략을 추진하고 있습니다.

1.  **1단계 (대한민국):** KT, SKT 등 국내 파트너들과의 협력을 통해 대규모 데이터센터 상용화 실적(Track Record)을 쌓습니다. 이를 통해 기술력과 제품의 안정성을 입증하고, 대규모 공급망 관리(SCM) 노하우를 축적합니다.
2.  **2단계 (소버린 AI 시장):** 한국에서의 성공 사례를 바탕으로, **'소버린 AI(Sovereign AI)'** 시장을 공략합니다. 소버린 AI란, 미국이나 중국의 기술 종속에서 벗어나 각 국가가 자체적으로 AI 인프라와 주권을 확보하려는 움직임입니다. 일본, 사우디아라비아, 두바이, 태국 등은 이러한 경향이 강하며, NVIDIA의 강력한 대안을 찾고 있어 리벨리온에게는 최적의 기회 시장입니다. 리벨리온은 이미 사우디와 일본에 현지 법인을 설립하고 본격적인 사업을 추진하고 있습니다.
3.  **3단계 (글로벌 하이퍼스케일러):** 소버린 AI 시장에서의 성공을 발판으로, 최종 목표인 미국 시장에 진출하여 아마존, 구글과 같은 글로벌 하이퍼스케일러 및 코히어(Cohere)와 같은 대형 LLM 개발사에 대규모 납품을 추진합니다.

### 결론: K-생태계와 함께 글로벌 추론 시장을 향해

리벨리온은 '추론'이라는 명확한 목표, 칩렛 기반의 혁신적인 기술, 그리고 소버린 AI라는 전략적 시장 진출 계획을 통해 NVIDIA의 대안을 넘어, AI 추론 시장의 글로벌 리더로 성장하고자 합니다. 삼성전자, SK하이닉스 등 강력한 국내 반도체 생태계와의 시너지를 바탕으로, 지난 5년의 준비를 마치고 내년부터 본격적인 글로벌 진출의 모멘텀을 만들어나갈 것입니다.

---

## 파트 2: 인텔(Intel)의 엔터프라이즈 AI를 위한 합리적 접근법

**발표자:** 조민성, 인텔코리아 데이터센터 기술 담당 상무

### 서론: AI 시장에 대한 인텔의 포지셔닝

인텔은 AI 시장 전체를 조망하며, '모든 AI 워크로드에 GPU가 필요한 것은 아니다'라는 실용적인 관점에서 접근합니다. 실제로 전체 AI 시장에서 생성형 AI가 차지하는 비중은 약 34%에 불과하며, 여전히 전통적인 머신러닝과 딥러닝이 큰 부분을 차지하고 있습니다. 인텔은 이러한 시장의 특성을 고려하여, 워크로드에 따라 CPU와 전용 가속기를 모두 활용하는 **이원화(Dual-Pronged) 전략**을 펼치고 있습니다.

### 전략: 워크로드에 맞는 최적의 하드웨어 선택

1.  **CPU가 충분한 영역:**
    *   **대상:** 전통적인 머신러닝, 소규모 딥러닝 추론, 그리고 생성형 AI의 핵심 기술인 **RAG(검색 증강 생성)** 파이프라인의 구성 요소(임베딩 모델, 벡터 DB 등).
    *   **솔루션:** 인텔의 **제온(Xeon) CPU**는 벡터 연산을 위한 **AVX-512**와 행렬 곱 연산을 위한 **AMX**라는 강력한 AI 가속 엔진을 내장하고 있습니다. 이러한 워크로드는 고가의 GPU 없이 제온 CPU만으로도 충분히 효율적으로 처리할 수 있으며, 이는 기업의 TCO(총소유비용)와 에너지 비용을 크게 절감시켜 줍니다.

2.  **전용 가속기가 필요한 영역:**
    *   **대상:** 대규모 생성형 AI 모델(200억 파라미터 이상)의 훈련, 파인튜닝, 그리고 대규모 추론.
    *   **솔루션:** 인텔은 이 영역을 위해 딥러닝 전용 가속기인 **가우디(Gaudi)** 시리즈를 제공합니다. 최신 제품인 **가우디 3**는 NVIDIA의 H100과 H200 사이의 성능에 위치하며, 특정 모델에서는 H200보다 높은 성능을 보이는 등 뛰어난 **가격 대비 성능**을 강점으로 내세우고 있습니다.

### 기업의 AI 도입 장벽을 낮추는 OPEA 프로젝트

많은 기업들이 AI를 도입하고 싶어하지만, 기술적 복잡성, 전문가 부족, 예상치 못한 비용 증가 등으로 어려움을 겪습니다. 상용 솔루션은 비용과 벤더 종속 문제가 있고, 오픈소스로 직접 구축하는 것은 시간과 노력이 너무 많이 듭니다.

인텔은 이 문제를 해결하기 위해 **OPEA(Open Platform for Enterprise AI)**라는 오픈소스 커뮤니티 프로젝트를 이끌고 있습니다.

*   **OPEA란?** 기업들이 손쉽게 생성형 AI, 특히 RAG 기반의 추론 서비스를 구축할 수 있도록, 필요한 소프트웨어들을 **컨테이너화된 모듈 형태**로 묶어 제공하는 **무료 레퍼런스 아키텍처**입니다.
*   **주요 특징 및 장점:**
    *   **간편한 배포:** 자동화된 스크립트를 통해 단 몇 시간 만에 프로덕션 수준의 안정적인 추론 서비스 배포가 가능합니다.
    *   **모듈식 구성:** vLLM 서빙 엔진, API 게이트웨이(Apache APISIX), 인증(Keycloak), 모니터링(Prometheus, Grafana) 등 필요한 모듈만 선택하여 커스터마이징할 수 있습니다.
    *   **OpenAI API 호환:** 생성된 API 엔드포인트는 OpenAI의 API 규격과 호환됩니다. 기존 애플리케이션 코드에서 **단 세 줄(API 키, URL, 모델명)만 수정**하면 즉시 인텔 기반의 인프라로 전환할 수 있습니다.
    *   **하드웨어 최적화:** 인텔 제온 및 가우디 하드웨어에 사전 최적화되어 있어, 사용자가 별도의 튜닝 작업을 할 필요가 없습니다.
    *   **유연한 사용 옵션:** 자체 서버에 직접 구축(On-premise)하거나, IBM 클라우드 등을 통해 서비스 형태로 이용할 수 있습니다.

### 결론: 기업을 위한 가장 합리적인 AI 도입 경로 제시

인텔의 AI 전략은 모든 것을 GPU로 해결하려는 획일적인 접근에서 벗어나, 기업의 현실적인 고민에 초점을 맞추고 있습니다. CPU만으로 충분한 워크로드는 제온 CPU를 통해 비용 효율적으로 처리하고, 고성능이 필요한 영역은 가우디 가속기로 대응하며 합리적인 대안을 제시합니다. 그리고 OPEA라는 강력한 오픈소스 소프트웨어 스택을 통해, 기업들이 복잡한 인프라 구축 과정 없이 AI 서비스를 빠르고 안정적으로 도입할 수 있도록 지원합니다. 이는 AI 도입을 고민하는 기업들에게 가장 실용적이고 경제적인 경로를 열어주는 전략입니다.
