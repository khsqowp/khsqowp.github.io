
---
title: "📝 NumPy & 데이터 분석 기초 강의 노트 (1일차)"
date: 2025-11-03
excerpt: "데이터 분석의 기초가 되는 NumPy 라이브러리의 핵심 개념인 배열(Array)과 벡터화 연산을 이해하고, 대용량 데이터를 효율적으로 처리하는 방법을 배웁니다."
categories:
  - Python
tags:
  - Python
  - SK_Rookies
---

- Python
  - Python
  - SK_Rookies

# 📝 NumPy & 데이터 분석 기초 강의 노트 (1일차)

> **강의일**: 2025년 11월 3일  
> **주제**: NumPy 배열과 벡터화 연산의 이해  
> **학습 목표**: 데이터 분석의 기초가 되는 NumPy 라이브러리 완벽 마스터하기


## 📌 학습 내용 개요

오늘 강의에서는 데이터 분석과 시각화를 위한 첫 번째 단계로 **NumPy(넘파이)** 라이브러리를 배웠습니다. 강사님께서는 Python 기본 문법만으로는 실제 데이터 분석이나 인공지능 개발을 할 수 없기 때문에, NumPy를 비롯한 서드파티 라이브러리들의 사용법을 익혀야 한다고 강조하셨습니다.

특히, **데이터 분석 → LLM 연동 → 랭체인(LangChain) → RAG**로 이어지는 학습 플로우를 고려하여, 데이터 분석을 먼저 진행한다고 설명하셨습니다. 이번 주에는 NumPy, Pandas, 데이터 시각화(Matplotlib, Seaborn), 그리고 Streamlit을 이용한 웹 대시보드까지 다룰 예정입니다.


## 🎯 NumPy가 필요한 이유 (Why NumPy?)

### 📖 배경: Python의 한계

강사님께서는 Python 기본 문법만으로는 데이터 분석이나 AI 개발이 어렵다고 말씀하셨습니다. Python은 **백엔드 개발**에는 적합하지만, 프론트엔드 개발은 불가능하며, 특히 **대용량 데이터를 빠르게 처리**하는 데에는 리스트(List)의 한계가 명확합니다.

### 🔑 핵심 문제점

1. **속도 문제**: Python의 리스트는 대용량 데이터를 처리할 때 반복문을 사용해야 하므로 느립니다.
2. **메모리 효율성**: 리스트는 각 요소가 다른 자료형을 가질 수 있어 메모리 효율이 떨어집니다.
3. **배열의 부재**: Python에는 기본적으로 배열(Array) 자료형이 없습니다.

> 💡 **중요!**: 인공지능에서 사용되는 데이터 타입은 **배열(Array)**입니다. 배열은 모든 요소가 같은 자료형을 가지며, 요소의 개수를 변경할 수 없다는 특징이 있습니다.

### ✅ NumPy가 제공하는 해결책

**NumPy(Numerical Python)**는 다음과 같은 장점을 제공합니다:

- **배열 데이터 타입**: 적은 메모리로 많은 양의 데이터를 빠르게 처리
- **벡터화 연산**: 반복문 없이 배열의 모든 요소에 대한 연산 수행
- **행렬 연산**: 선형대수 연산 지원
- **수학 및 통계 함수**: 다양한 수학적 계산 기능 제공

> 📌 **노트**: NumPy는 데이터 분석의 기초가 되는 라이브러리입니다. NumPy를 이해하지 못하면 Pandas, 인공지능 라이브러리를 제대로 활용할 수 없습니다.


## 🚀 NumPy 시작하기

### 1️⃣ NumPy 설치 및 확인

NumPy는 서드파티 라이브러리이므로 설치가 필요합니다. Anaconda를 사용하는 경우 이미 설치되어 있습니다.

**설치 확인 방법 (Anaconda Prompt 사용)**:

```bash
pip show numpy
```

강사님께서 확인하신 결과, NumPy 2.13 버전이 설치되어 있었고, Python 버전은 3.13이었습니다.

> 🔐 **보안 노트**: **버전 호환성 문제**는 Python 개발에서 가장 많이 발생하는 이슈입니다. 서드파티 라이브러리들은 서로 의존 관계를 가지고 있어, Python 버전과 라이브러리 버전이 맞지 않으면 오류가 발생할 수 있습니다. 예를 들어, LangChain 1.3 이상 버전을 사용하려면 특정 Python 버전이 필요할 수 있습니다. 이런 이유로 **가상 환경(Virtual Environment)**을 사용하는 것이 권장됩니다.

### 2️⃣ NumPy 임포트

NumPy를 사용하려면 먼저 임포트해야 합니다.

```python
import numpy as np
```

> 📌 **노트**: `np`는 NumPy의 관례적인 별칭(alias)입니다. 전 세계 개발자들이 공통적으로 사용하는 표준 별칭이므로 반드시 `np`를 사용하세요.


## 📊 NumPy 배열의 기초

### 🔍 리스트 vs 배열 비교

#### Python 리스트 생성

```python
lst = [1, 2, 3, 4, 5]
print(f"파이썬 리스트: {lst}, 타입: {type(lst)}")
```

**출력 결과**:
```
파이썬 리스트: [1, 2, 3, 4, 5], 타입: <class 'list'>
```

#### #### 💻 코드 실행 상세 분석

**1단계 (리스트 생성)**: `lst` 변수에 1부터 5까지의 정수를 담은 리스트가 할당됩니다.

**2단계 (타입 확인)**: `type(lst)` 함수를 통해 `lst`의 자료형을 확인하면 `<class 'list'>`가 반환됩니다. 이는 Python의 기본 자료형인 리스트임을 의미합니다.

**최종 결과**: 리스트는 Python의 기본 자료형으로, 다양한 자료형의 요소를 담을 수 있지만 대용량 데이터 처리에는 효율적이지 않습니다.


#### NumPy 배열로 변환

```python
arr = np.array(lst)
print(f"NumPy 배열: {arr}, 타입: {type(arr)}")
```

**출력 결과**:
```
NumPy 배열: [1 2 3 4 5], 타입: <class 'numpy.ndarray'>
```

#### 💻 코드 실행 상세 분석

**1단계 (배열 변환)**: `np.array(lst)` 함수를 사용하여 Python 리스트를 NumPy 배열(`ndarray`)로 변환합니다.

**2단계 (타입 확인)**: `type(arr)`를 확인하면 `<class 'numpy.ndarray'>`가 반환됩니다. `ndarray`는 N-dimensional array의 약자로, N차원 배열을 의미합니다.

**최종 결과**: 동일한 데이터지만, 자료형이 리스트에서 NumPy 배열로 변경되었습니다. 이제 벡터화 연산과 같은 강력한 기능을 사용할 수 있습니다.

> 💡 **중요!**: NumPy 배열은 **모든 요소가 같은 자료형**이어야 합니다. 이는 메모리 효율성과 연산 속도를 높이기 위한 설계입니다.


### 🔎 배열 정보 확인 함수 만들기

배열의 주요 정보를 한 번에 확인할 수 있는 함수를 정의했습니다.

```python
def array_info(array):
    """NumPy 배열의 주요 정보(데이터, shape, 차원, dtype)를 출력하는 함수"""
    if not isinstance(array, np.ndarray):
        print("입력값은 NumPy 배열이 아닙니다.")
        return
    print(f"데이터: {array}")
    print(f"Shape (형태): {array.shape}")
    print(f"Dimension (차원): {array.ndim}")
    print(f"Data Type (자료형): {array.dtype}")
    print("-" * 20)
```

**사용 예제**:

```python
array_info(arr)
```

**출력 결과**:
```
데이터: [1 2 3 4 5]
Shape (형태): (5,)
Dimension (차원): 1
Data Type (자료형): int64
--------------------
```

#### 💻 코드 실행 상세 분석

**1단계 (타입 검증)**: `isinstance(array, np.ndarray)`를 통해 입력값이 NumPy 배열인지 확인합니다. 배열이 아니면 에러 메시지를 출력하고 함수를 종료합니다.

**2단계 (배열 정보 출력)**:
- `array.shape`: 배열의 형태를 튜플로 반환합니다. `(5,)`는 5개의 요소를 가진 1차원 배열을 의미합니다.
- `array.ndim`: 배열의 차원을 정수로 반환합니다. 1차원 배열이므로 `1`이 반환됩니다.
- `array.dtype`: 배열 요소의 자료형을 반환합니다. `int64`는 64비트 정수형을 의미합니다.

**최종 결과**: 이 함수를 사용하면 배열의 주요 정보를 한눈에 파악할 수 있어, 디버깅과 데이터 분석 시 매우 유용합니다.

> 📌 **노트**: 강사님께서는 이 함수를 실습 내내 사용하셨으며, 배열을 다룰 때마다 `shape`, `ndim`, `dtype`을 확인하는 습관을 들이는 것이 중요하다고 강조하셨습니다.


### 📐 배열의 주요 속성 이해하기

NumPy 배열이 가지는 핵심 속성은 다음과 같습니다:

1. **shape (형태)**: 배열의 각 차원의 크기를 나타내는 튜플
2. **ndim (차원)**: 배열의 차원 수 (1차원, 2차원, 3차원 등)
3. **dtype (자료형)**: 배열에 저장된 요소들의 데이터 타입

#### 개념 증명 코드: dtype의 일관성

NumPy 배열의 모든 요소는 같은 자료형을 가져야 한다는 특징을 증명하는 코드입니다.

```python
# 정수와 실수를 섞어서 배열 생성
mixed_arr = np.array([1, 2, 3.5, 4])
print(f"배열: {mixed_arr}")
print(f"dtype: {mixed_arr.dtype}")
```

**출력 결과**:
```
배열: [1.  2.  3.5 4. ]
dtype: float64
```

#### 💻 코드 실행 상세 분석

**1단계 (배열 생성)**: 정수 `1, 2, 4`와 실수 `3.5`를 담은 리스트로 배열을 생성합니다.

**2단계 (자동 형변환)**: NumPy는 **모든 요소가 같은 자료형**이어야 하므로, 정수들을 자동으로 실수(float64)로 변환합니다. 이를 **묵시적 형변환(Implicit Type Casting)**이라고 합니다.

**최종 결과**: 배열의 모든 요소가 실수형으로 변환되어 `[1.  2.  3.5 4. ]`가 출력되며, `dtype`은 `float64`입니다.

> 💡 **중요!**: NumPy는 항상 "더 포괄적인" 자료형으로 자동 변환합니다. 정수와 실수가 섞여 있으면 모두 실수로, 숫자와 문자열이 섞여 있으면 모두 문자열로 변환됩니다.


## ⚡ 벡터화 연산 (Vectorization)

### 📖 벡터화 연산이란?

**벡터화 연산**은 배열의 각 요소에 대해 반복문 없이 한 번에 연산을 수행하는 NumPy의 핵심 기능입니다. 이는 **성능 최적화**와 **코드 간결성** 두 가지 장점을 동시에 제공합니다.

강사님께서는 "벡터화 연산이 NumPy의 가장 중요한 개념"이라고 강조하셨습니다.

### 🐌 리스트의 한계: 반복문 필요

Python 리스트로 각 요소를 제곱하려면 반복문을 사용해야 합니다.

```python
lst = [1, 2, 3, 4, 5]

# 방법 1: for 루프 사용
result_list = []
for element in lst:
    result_list.append(element ** 2)
print(f"리스트 연산 (반복문): {result_list}")
```

**출력 결과**:
```
리스트 연산 (반복문): [1, 4, 9, 16, 25]
```

#### 💻 코드 실행 상세 분석

**1단계 (빈 리스트 생성)**: `result_list`라는 빈 리스트를 생성합니다.

**2단계 (반복문 실행)**: `for` 루프를 통해 `lst`의 각 요소를 순회합니다.

**3단계 (제곱 연산 및 추가)**: 각 요소를 제곱(`element ** 2`)하고, 결과를 `result_list`에 추가(`append`)합니다.

**최종 결과**: 5개의 요소에 대해 5번의 반복이 필요하며, 리스트에 제곱된 값들이 저장됩니다.

> 📌 **노트**: 이 방법은 요소가 5개일 때는 괜찮지만, 100만 개, 1억 개의 데이터를 처리할 때는 매우 느려집니다.


#### 리스트에 직접 연산 시도하면?

```python
try:
    result = lst ** 2
except TypeError as e:
    print(f"리스트에 직접 연산 시도 시 에러: {e}")
```

**출력 결과**:
```
리스트에 직접 연산 시도 시 에러: unsupported operand type(s) for ** or pow(): 'list' and 'int'
```

#### 💻 코드 실행 상세 분석

**1단계 (연산 시도)**: 리스트에 직접 `** 2` 연산을 시도합니다.

**2단계 (에러 발생)**: Python 리스트는 산술 연산을 지원하지 않으므로 `TypeError`가 발생합니다.

**최종 결과**: 리스트는 벡터화 연산을 지원하지 않으므로, 반복문을 사용해야만 합니다.


### ⚡ NumPy의 벡터화 연산

NumPy 배열은 **벡터화 연산**을 지원하여 반복문 없이 모든 요소에 연산을 적용할 수 있습니다.

```python
arr = np.array([1, 2, 3, 4, 5])
result_arr = arr ** 2
print(f"NumPy 배열 연산 (벡터화): {result_arr}")
```

**출력 결과**:
```
NumPy 배열 연산 (벡터화): [ 1  4  9 16 25]
```

#### 💻 코드 실행 상세 분석

**1단계 (배열 생성)**: NumPy 배열 `arr`를 생성합니다.

**2단계 (벡터화 연산)**: `arr ** 2`를 실행하면 NumPy가 내부적으로 최적화된 C 언어 코드를 실행하여 모든 요소를 제곱합니다. **반복문이 명시적으로 필요하지 않습니다.**

**최종 결과**: 단 한 줄의 코드로 모든 요소의 제곱을 계산하며, 속도도 리스트 방식보다 훨씬 빠릅니다.

> 💡 **중요!**: NumPy의 벡터화 연산은 **C 언어로 최적화된 라이브러리**를 내부적으로 사용하므로, Python의 반복문보다 10배~100배 이상 빠릅니다.


### 🔢 배열 간의 연산

두 배열 간의 연산도 벡터화됩니다.

```python
x_arr = np.array([1, 2, 3])
y_arr = np.array([4, 5, 6])

print(f"배열 덧셈: {x_arr} + {y_arr} = {x_arr + y_arr}")
```

**출력 결과**:
```
배열 덧셈: [1 2 3] + [4 5 6] = [5 7 9]
```

#### 💻 코드 실행 상세 분석

**1단계 (두 배열 생성)**: `x_arr`와 `y_arr` 두 개의 1차원 배열을 생성합니다.

**2단계 (요소별 덧셈)**: `x_arr + y_arr`를 실행하면 같은 위치의 요소끼리 더해집니다 (element-wise addition).
- `x_arr[0] + y_arr[0]` = 1 + 4 = 5
- `x_arr[1] + y_arr[1]` = 2 + 5 = 7
- `x_arr[2] + y_arr[2]` = 3 + 6 = 9

**최종 결과**: `[5 7 9]`라는 새로운 배열이 반환됩니다.

> 📌 **노트**: 배열 간 연산은 **요소별 연산(Element-wise Operation)**이 기본입니다. 덧셈, 뺄셈, 곱셈, 나눗셈 모두 동일하게 작동합니다.


### 🔄 벡터화 연산의 다양한 예제

```python
# 산술 연산
print(f"배열 뺄셈: {x_arr - y_arr}")
print(f"배열 곱셈: {x_arr * y_arr}")
print(f"배열 나눗셈: {y_arr / x_arr}")

# 비교 연산
print(f"비교 연산 (x == 2): {x_arr == 2}")
print(f"비교 연산 (y > 4): {y_arr > 4}")

# 논리 연산
print(f"논리 AND 연산: {(x_arr == 2) & (y_arr > 4)}")
```

**출력 결과**:
```
배열 뺄셈: [-3 -3 -3]
배열 곱셈: [ 4 10 18]
배열 나눗셈: [4.  2.5 2. ]
비교 연산 (x == 2): [False  True False]
비교 연산 (y > 4): [False  True  True]
논리 AND 연산: [False  True False]
```

#### 💻 코드 실행 상세 분석

**산술 연산 단계**:
- 뺄셈: 각 위치의 요소를 뺍니다 → `[1-4, 2-5, 3-6]` = `[-3, -3, -3]`
- 곱셈: 각 위치의 요소를 곱합니다 → `[1*4, 2*5, 3*6]` = `[4, 10, 18]`
- 나눗셈: 각 위치의 요소를 나눕니다 → `[4/1, 5/2, 6/3]` = `[4.0, 2.5, 2.0]`

**비교 연산 단계**:
- `x_arr == 2`: 각 요소가 2와 같은지 확인 → `[False, True, False]`
- `y_arr > 4`: 각 요소가 4보다 큰지 확인 → `[False, True, True]`

**논리 연산 단계**:
- `&` (AND 연산): 두 조건을 모두 만족하는지 확인 → `[False, True, False]`

**최종 결과**: NumPy는 산술, 비교, 논리 연산 모두를 벡터화하여 지원합니다.

> 💡 **중요!**: 논리 연산 시 `and`/`or` 키워드가 아닌 `&`/`|` 기호를 사용해야 합니다. 그리고 각 조건을 괄호로 묶어야 합니다.


## 🎭 불리언 마스킹 (Boolean Masking)

### 📖 불리언 마스킹이란?

**불리언 마스킹(Boolean Masking)**은 조건에 맞는 요소만 필터링하는 강력한 기법입니다. 이는 데이터 분석에서 특정 조건을 만족하는 데이터를 추출할 때 매우 유용합니다.

### 🔍 기본 불리언 마스킹

```python
arr = np.array([1, 2, 3, 4, 5])

# 조건: 3보다 큰 요소 찾기
bool_mask = arr > 3
print(f"arr > 3 의 결과 (불리언 마스크): {bool_mask}")

# 불리언 마스크로 필터링
filtered = arr[bool_mask]
print(f"arr[arr > 3] 의 결과 (필터링된 값): {filtered}")
```

**출력 결과**:
```
arr > 3 의 결과 (불리언 마스크): [False False False  True  True]
arr[arr > 3] 의 결과 (필터링된 값): [4 5]
```

#### 💻 코드 실행 상세 분석

**1단계 (불리언 마스크 생성)**: `arr > 3` 비교 연산을 수행하면 각 요소가 3보다 큰지 확인하여 `True`/`False` 배열을 반환합니다.
- `arr[0]` (1) > 3? → False
- `arr[1]` (2) > 3? → False
- `arr[2]` (3) > 3? → False
- `arr[3]` (4) > 3? → True
- `arr[4]` (5) > 3? → True

**2단계 (마스킹 적용)**: 불리언 배열 `bool_mask`를 인덱스로 사용하면, `True`인 위치의 요소만 선택됩니다.

**최종 결과**: `arr[bool_mask]`는 `[4, 5]`를 반환합니다. 이는 3보다 큰 요소만 필터링된 결과입니다.

> 📌 **노트**: 불리언 마스킹은 SQL의 `WHERE` 절과 유사한 역할을 합니다. 특정 조건을 만족하는 데이터만 선택할 수 있습니다.


### 🎯 복합 조건 마스킹

여러 조건을 조합하여 복잡한 필터링도 가능합니다.

```python
# 복합 조건: arr에서 2와 같거나 4보다 큰 요소 찾기
complex_mask = (arr == 2) | (arr > 4)
print(f"(arr == 2) | (arr > 4) 의 결과: {arr[complex_mask]}")
```

**출력 결과**:
```
(arr == 2) | (arr > 4) 의 결과: [2 5]
```

#### 💻 코드 실행 상세 분석

**1단계 (첫 번째 조건)**: `arr == 2`는 `[False, True, False, False, False]`를 반환합니다.

**2단계 (두 번째 조건)**: `arr > 4`는 `[False, False, False, False, True]`를 반환합니다.

**3단계 (OR 연산)**: `|` 연산자로 두 불리언 배열을 결합하면 `[False, True, False, False, True]`가 됩니다.

**4단계 (마스킹 적용)**: 최종 불리언 배열을 사용하여 `arr`를 필터링하면 `[2, 5]`가 반환됩니다.

**최종 결과**: "2와 같거나" 또는 "4보다 큰" 요소만 선택됩니다.

> 💡 **중요!**: 
> - `&`: AND 연산 (두 조건 모두 만족)
> - `|`: OR 연산 (두 조건 중 하나라도 만족)
> - `~`: NOT 연산 (조건을 반전)


### 🧪 개념 증명 코드: 불리언 마스킹의 활용

```python
# 예제: 짝수만 필터링하기
numbers = np.arange(10)  # [0, 1, 2, ..., 9]
even_mask = numbers % 2 == 0
print(f"원본 배열: {numbers}")
print(f"짝수 마스크: {even_mask}")
print(f"짝수만 추출: {numbers[even_mask]}")
```

**출력 결과**:
```
원본 배열: [0 1 2 3 4 5 6 7 8 9]
짝수 마스크: [ True False  True False  True False  True False  True False]
짝수만 추출: [0 2 4 6 8]
```

#### 💻 코드 실행 상세 분석

**1단계 (배열 생성)**: `np.arange(10)`으로 0부터 9까지의 배열을 생성합니다.

**2단계 (짝수 판별)**: `numbers % 2 == 0` 연산으로 각 숫자를 2로 나눈 나머지가 0인지 확인합니다.

**3단계 (마스킹)**: `True`인 위치 (짝수)의 요소만 선택됩니다.

**최종 결과**: 짝수만 담긴 `[0, 2, 4, 6, 8]` 배열이 반환됩니다.


## 📊 2차원 배열 (행렬, Matrix)

### 📖 2차원 배열의 개념

강사님께서는 "배열은 행렬로 표현할 수 있다"고 설명하셨습니다. 2차원 배열은 **행(row)**과 **열(column)**로 구성된 표 형태의 데이터 구조입니다.

### 🏗️ 2차원 배열 생성

Python의 **리스트의 리스트(List of List)**를 사용하여 2차원 배열을 생성할 수 있습니다.

```python
# 2 x 3 배열 생성 (2행 3열)
list_of_list = [[1, 2, 3], [4, 5, 6]]
arr_2d = np.array(list_of_list)

print("--- 2차원 배열 정보 ---")
array_info(arr_2d)
```

**출력 결과**:
```
--- 2차원 배열 정보 ---
데이터: [[1 2 3]
 [4 5 6]]
Shape (형태): (2, 3)
Dimension (차원): 2
Data Type (자료형): int64
--------------------
```

#### 💻 코드 실행 상세 분석

**1단계 (리스트의 리스트 생성)**: `[[1, 2, 3], [4, 5, 6]]`는 2개의 리스트를 담은 리스트입니다.
- 첫 번째 리스트 `[1, 2, 3]`: 첫 번째 행
- 두 번째 리스트 `[4, 5, 6]`: 두 번째 행

**2단계 (NumPy 배열로 변환)**: `np.array(list_of_list)`를 호출하면 2차원 배열로 변환됩니다.

**3단계 (shape 확인)**: `shape`가 `(2, 3)`이라는 것은 2행 3열을 의미합니다.
- 첫 번째 숫자 `2`: 행의 개수
- 두 번째 숫자 `3`: 열의 개수

**최종 결과**: 2차원 배열이 생성되며, `ndim`은 2, `shape`는 (2, 3)이 됩니다.

> 💡 **중요!**: `shape`의 순서는 항상 **(행의 개수, 열의 개수)**입니다. 이는 수학의 행렬 표기법과 동일합니다.


### 🎯 2차원 배열의 인덱싱

2차원 배열의 요소에 접근하는 방법은 두 가지입니다.

```python
# 1행 2열의 값 (6) 접근
print(f"arr_2d[1, 2]: {arr_2d[1, 2]}")
print(f"arr_2d[1][2]: {arr_2d[1][2]}")
```

**출력 결과**:
```
arr_2d[1, 2]: 6
arr_2d[1][2]: 6
```

#### 💻 코드 실행 상세 분석

**방법 1: 콤마로 구분**
- `arr_2d[1, 2]`: NumPy의 권장 방식입니다. 행 인덱스 1, 열 인덱스 2를 의미합니다.
- 인덱스는 0부터 시작하므로 두 번째 행(1)의 세 번째 열(2)을 가리킵니다.

**방법 2: 이중 대괄호**
- `arr_2d[1][2]`: Python 리스트 방식입니다. `arr_2d[1]`로 먼저 두 번째 행을 가져오고, 그 중 `[2]` 인덱스를 선택합니다.

**최종 결과**: 두 방법 모두 동일한 값 `6`을 반환하지만, **NumPy 방식(`arr_2d[1, 2]`)이 더 효율적이고 권장**됩니다.

> 📌 **노트**: NumPy 방식을 사용하면 슬라이싱과 팬시 인덱싱을 더 쉽게 사용할 수 있습니다.


### 📏 len() 함수의 동작

```python
print(f"len(arr_2d): {len(arr_2d)}")       # 행의 개수
print(f"len(arr_2d[0]): {len(arr_2d[0])}")  # 첫 번째 행의 열 개수
print(f"len(arr_2d[1]): {len(arr_2d[1])}")  # 두 번째 행의 열 개수
```

**출력 결과**:
```
len(arr_2d): 2
len(arr_2d[0]): 3
len(arr_2d[1]): 3
```

#### 💻 코드 실행 상세 분석

**1단계 (`len(arr_2d)`)**: 2차원 배열의 길이는 **첫 번째 차원(행)의 개수**를 반환합니다.

**2단계 (`len(arr_2d[0])`)**: `arr_2d[0]`는 첫 번째 행 `[1, 2, 3]`을 의미하며, 이 행의 길이는 3입니다.

**최종 결과**: `len()` 함수는 항상 첫 번째 차원의 크기를 반환합니다.

> 💡 **중요!**: 다차원 배열에서 `len()`은 항상 첫 번째 차원만 반환합니다. 전체 크기를 알려면 `shape` 속성을 사용하세요.


## 🏗️ 배열 생성 함수

### 🔢 arange() 함수

`np.arange()`는 Python의 `range()`와 유사하지만 NumPy 배열을 반환합니다.

```python
# 0부터 11까지의 값을 갖는 1차원 배열 생성
arr_range = np.arange(12)
print(f"np.arange(12): {arr_range}")
```

**출력 결과**:
```
np.arange(12): [ 0  1  2  3  4  5  6  7  8  9 10 11]
```

#### 💻 코드 실행 상세 분석

**1단계 (배열 생성)**: `np.arange(12)`는 0부터 시작하여 12 미만의 정수를 생성합니다.

**2단계 (반환)**: 총 12개의 요소를 가진 1차원 NumPy 배열이 반환됩니다.

**최종 결과**: `range()`와 달리 바로 배열로 생성되므로 리스트 변환이 필요 없습니다.

> 📌 **노트**: `np.arange(start, stop, step)` 형태로 시작값, 종료값, 간격을 지정할 수 있습니다.


### 🔄 reshape() 함수

`reshape()`는 배열의 형태를 변경하는 함수입니다. **요소의 총 개수는 동일해야 합니다.**

```python
# 1차원 배열을 3행 4열의 2차원 배열로 변형
arr_reshaped = arr_range.reshape(3, 4)
print("--- reshape(3, 4) 후 ---")
array_info(arr_reshaped)
```

**출력 결과**:
```
--- reshape(3, 4) 후 ---
데이터: [[ 0  1  2  3]
 [ 4  5  6  7]
 [ 8  9 10 11]]
Shape (형태): (3, 4)
Dimension (차원): 2
Data Type (자료형): int64
--------------------
```

#### 💻 코드 실행 상세 분석

**1단계 (원본 배열)**: 12개의 요소를 가진 1차원 배열 `[0, 1, ..., 11]`

**2단계 (reshape 실행)**: `.reshape(3, 4)`를 호출하면 3행 4열 형태로 변경됩니다.
- 0행: `[0, 1, 2, 3]`
- 1행: `[4, 5, 6, 7]`
- 2행: `[8, 9, 10, 11]`

**3단계 (검증)**: 3 x 4 = 12이므로 요소의 총 개수가 동일하여 변형이 가능합니다.

**최종 결과**: 1차원 배열이 2차원 배열로 변환되었으며, `shape`는 `(3, 4)`, `ndim`은 2가 됩니다.

> 💡 **중요!**: `reshape()`를 사용할 때는 **원본 요소의 개수 = 새로운 shape의 곱**이어야 합니다. 그렇지 않으면 `ValueError`가 발생합니다.


### 🎯 -1을 사용한 자동 계산

`reshape()`에서 한 차원을 `-1`로 지정하면 NumPy가 자동으로 계산합니다.

```python
# 1부터 20까지의 배열을 4행 ?열로 변경
arr_auto_reshape = np.arange(1, 21).reshape(4, -1)
print("--- reshape(4, -1) 후 ---")
array_info(arr_auto_reshape)
```

**출력 결과**:
```
--- reshape(4, -1) 후 ---
데이터: [[ 1  2  3  4  5]
 [ 6  7  8  9 10]
 [11 12 13 14 15]
 [16 17 18 19 20]]
Shape (형태): (4, 5)
Dimension (차원): 2
Data Type (자료형): int64
--------------------
```

#### 💻 코드 실행 상세 분석

**1단계 (배열 생성)**: `np.arange(1, 21)`로 1부터 20까지 20개 요소 생성

**2단계 (자동 계산)**: `reshape(4, -1)`에서 `-1`은 "나머지 차원을 자동으로 계산하라"는 의미입니다.
- 총 요소 개수: 20개
- 지정된 행: 4행
- 자동 계산: 20 ÷ 4 = 5열

**최종 결과**: NumPy가 자동으로 열의 개수를 5로 계산하여 `(4, 5)` 형태의 배열을 생성합니다.

> 📌 **노트**: `-1`은 한 번만 사용할 수 있으며, 나머지 차원은 명시적으로 지정해야 합니다.


## 🎨 팬시 인덱싱 (Fancy Indexing)

### 📖 팬시 인덱싱이란?

**팬시 인덱싱(Fancy Indexing)**은 배열이나 리스트를 인덱스로 사용하여 원하는 요소들을 한 번에 선택하는 기법입니다. 강사님께서는 "이 개념이 Pandas에서도 계속 사용되므로 중요하다"고 강조하셨습니다.

팬시 인덱싱에는 두 가지 종류가 있습니다:
1. **정수 인덱싱 (Integer Indexing)**: 정수 배열을 인덱스로 사용
2. **불리언 인덱싱 (Boolean Indexing)**: 불리언 배열을 인덱스로 사용 (앞서 배운 불리언 마스킹)

### 🔢 1차원 배열에서의 팬시 인덱싱

```python
# 1차원 배열 생성
arr_fancy = np.arange(10)
print(f"원본 배열: {arr_fancy}")

# 방법 1: 불리언 인덱싱 (짝수만 출력)
even_mask = arr_fancy % 2 == 0
print(f"짝수만 출력 (불리언): {arr_fancy[even_mask]}")

# 방법 2: 정수 인덱싱 (짝수 인덱스만)
even_indices = [0, 2, 4, 6, 8]
print(f"짝수 인덱스 값 출력 (정수): {arr_fancy[even_indices]}")
```

**출력 결과**:
```
원본 배열: [0 1 2 3 4 5 6 7 8 9]
짝수만 출력 (불리언): [0 2 4 6 8]
짝수 인덱스 값 출력 (정수): [0 2 4 6 8]
```

#### 💻 코드 실행 상세 분석

**방법 1: 불리언 인덱싱**

**1단계 (불리언 마스크 생성)**: `arr_fancy % 2 == 0`으로 짝수를 판별하는 불리언 배열 생성
- `[True, False, True, False, ...]`

**2단계 (마스킹)**: `arr_fancy[even_mask]`로 `True` 위치의 요소만 선택

**최종 결과**: 짝수 `[0, 2, 4, 6, 8]`이 반환됩니다.


**방법 2: 정수 인덱싱**

**1단계 (인덱스 리스트 생성)**: `[0, 2, 4, 6, 8]` 리스트를 만듭니다.

**2단계 (인덱싱)**: `arr_fancy[even_indices]`를 실행하면 해당 인덱스 위치의 요소들을 선택합니다.
- `arr_fancy[0]` → 0
- `arr_fancy[2]` → 2
- `arr_fancy[4]` → 4
- `arr_fancy[6]` → 6
- `arr_fancy[8]` → 8

**최종 결과**: `[0, 2, 4, 6, 8]`이 반환되며, 결과는 불리언 인덱싱과 동일합니다.

> 💡 **중요!**: 정수 인덱싱은 **순서와 중복**을 자유롭게 제어할 수 있습니다. 예: `[0, 0, 5, 3]`처럼 같은 인덱스를 여러 번 사용하거나 순서를 바꿀 수 있습니다.


### 🎯 2차원 배열에서의 팬시 인덱싱

2차원 배열에서의 팬시 인덱싱은 더욱 강력합니다.

```python
# 2차원 배열 생성
arr_2d_fancy = np.arange(1, 13).reshape(3, 4)
print("원본 2차원 배열:")
print(arr_2d_fancy)

# 모든 행에 대해 0번째, 3번째 열 가져오기
print("모든 행의 0, 3열:")
print(arr_2d_fancy[:, [0, 3]])

# 0번째, 2번째 행을 선택하고, 그 안에서 1번째, 3번째 열 선택
print("0, 2행 & 1, 3열:")
print(arr_2d_fancy[[0, 2]][:, [1, 3]])
```

**출력 결과**:
```
원본 2차원 배열:
[[ 1  2  3  4]
 [ 5  6  7  8]
 [ 9 10 11 12]]

모든 행의 0, 3열:
[[ 1  4]
 [ 5  8]
 [ 9 12]]

0, 2행 & 1, 3열:
[[ 2  4]
 [10 12]]
```

#### 💻 코드 실행 상세 분석

**예제 1: 모든 행의 특정 열 선택**

**1단계 (슬라이싱)**: `arr_2d_fancy[:, [0, 3]]`
- `:`: 모든 행 선택
- `[0, 3]`: 0번째 열과 3번째 열 선택

**2단계 (결과 구성)**:
- 0행의 0, 3열 → `[1, 4]`
- 1행의 0, 3열 → `[5, 8]`
- 2행의 0, 3열 → `[9, 12]`

**최종 결과**: `(3, 2)` 형태의 배열이 반환됩니다.


**예제 2: 특정 행과 특정 열 동시 선택**

**1단계 (행 선택)**: `arr_2d_fancy[[0, 2]]`
- 0번째 행과 2번째 행을 선택 → `[[1, 2, 3, 4], [9, 10, 11, 12]]`

**2단계 (열 선택)**: `[:, [1, 3]]`
- 모든 행에서 1번째 열과 3번째 열 선택

**3단계 (결과 구성)**:
- 0행의 1, 3열 → `[2, 4]`
- 2행의 1, 3열 → `[10, 12]`

**최종 결과**: `(2, 2)` 형태의 배열 `[[2, 4], [10, 12]]`가 반환됩니다.

> 📌 **노트**: 2차원 팬시 인덱싱의 핵심은 **행과 열을 독립적으로 제어**할 수 있다는 점입니다. 이는 Pandas DataFrame에서도 동일하게 작동합니다.


## 📈 통계 함수

### 📖 NumPy의 통계 함수

NumPy는 다양한 통계 함수를 제공하여 데이터 분석을 쉽게 만들어줍니다. 강사님께서는 "통계 함수는 Pandas에서도 계속 사용되므로 반드시 익혀야 한다"고 강조하셨습니다.

### 🔢 기본 통계 함수

```python
# 4x4 배열 생성
stats_arr = np.arange(1, 17).reshape(4, 4)
print("원본 배열:")
print(stats_arr)

print(f"전체 합 (sum): {np.sum(stats_arr)}")
print(f"전체 평균 (mean): {np.mean(stats_arr)}")
print(f"전체 최댓값 (max): {np.max(stats_arr)}")
```

**출력 결과**:
```
원본 배열:
[[ 1  2  3  4]
 [ 5  6  7  8]
 [ 9 10 11 12]
 [13 14 15 16]]
전체 합 (sum): 136
전체 평균 (mean): 8.5
전체 최댓값 (max): 16
```

#### 💻 코드 실행 상세 분석

**1단계 (배열 생성)**: 1부터 16까지의 연속된 정수로 4x4 배열 생성

**2단계 (전체 합 계산)**: `np.sum(stats_arr)`
- 배열의 모든 요소를 더함: 1 + 2 + ... + 16 = 136

**3단계 (전체 평균 계산)**: `np.mean(stats_arr)`
- 전체 합을 요소 개수로 나눔: 136 ÷ 16 = 8.5

**4단계 (전체 최댓값)**: `np.max(stats_arr)`
- 배열에서 가장 큰 값: 16

**최종 결과**: 배열의 통계적 특성을 한 번에 파악할 수 있습니다.


### 📐 축(axis) 기반 통계

**축(axis)** 개념은 다차원 배열에서 매우 중요합니다. 강사님께서는 "축의 방향을 헷갈려하는 경우가 많으니 명확하게 기억하라"고 하셨습니다.

> 💡 **중요!**: 
> - `axis=0`: **열 방향** (각 열에 대한 연산)
> - `axis=1`: **행 방향** (각 행에 대한 연산)

```python
# axis 사용: 0=열 기준, 1=행 기준
print(f"열 기준 합 (axis=0): {np.sum(stats_arr, axis=0)}")
print(f"행 기준 합 (axis=1): {np.sum(stats_arr, axis=1)}")
```

**출력 결과**:
```
열 기준 합 (axis=0): [28 32 36 40]
행 기준 합 (axis=1): [10 26 42 58]
```

#### 💻 코드 실행 상세 분석

**axis=0 (열 기준 합)**

**1단계 (열별 계산)**: 각 열의 요소들을 모두 더합니다.
- 0열: 1 + 5 + 9 + 13 = 28
- 1열: 2 + 6 + 10 + 14 = 32
- 2열: 3 + 7 + 11 + 15 = 36
- 3열: 4 + 8 + 12 + 16 = 40

**최종 결과**: `[28, 32, 36, 40]` 배열 반환 (4개의 열에 대한 합)


**axis=1 (행 기준 합)**

**1단계 (행별 계산)**: 각 행의 요소들을 모두 더합니다.
- 0행: 1 + 2 + 3 + 4 = 10
- 1행: 5 + 6 + 7 + 8 = 26
- 2행: 9 + 10 + 11 + 12 = 42
- 3행: 13 + 14 + 15 + 16 = 58

**최종 결과**: `[10, 26, 42, 58]` 배열 반환 (4개의 행에 대한 합)

> 📌 **노트**: `axis` 매개변수는 "어떤 축을 따라 연산을 수행할지"를 지정합니다. 결과는 지정한 축이 제거된 형태로 반환됩니다.


### 🎯 argmin, argmax 함수

```python
# argmin, argmax: 최소/최대값의 '인덱스' 반환
print(f"전체에서 최솟값의 인덱스 (flatten 기준): {np.argmin(stats_arr)}")
print(f"전체에서 최댓값의 인덱스 (flatten 기준): {np.argmax(stats_arr)}")
```

**출력 결과**:
```
전체에서 최솟값의 인덱스 (flatten 기준): 0
전체에서 최댓값의 인덱스 (flatten 기준): 15
```

#### 💻 코드 실행 상세 분석

**1단계 (배열 평탄화)**: 2차원 배열을 1차원으로 펼쳤다고 가정합니다.
- 평탄화된 배열: `[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]`

**2단계 (최솟값 인덱스)**: `np.argmin(stats_arr)`
- 가장 작은 값은 `1`
- 인덱스는 `0`

**3단계 (최댓값 인덱스)**: `np.argmax(stats_arr)`
- 가장 큰 값은 `16`
- 인덱스는 `15`

**최종 결과**: 값 자체가 아닌 **인덱스**가 반환됩니다.

> 💡 **중요!**: `argmin`/`argmax`는 "값"이 아닌 "인덱스"를 반환합니다. 이는 특정 조건을 만족하는 데이터의 위치를 찾을 때 유용합니다.


### 🧩 실전 예제: 행/열 통계 추가하기

강의 중 제시된 Quiz 문제입니다.

```python
# 5x6 랜덤 배열 생성
ary = np.random.randint(1, 1000000, (5, 6))
print("원본 배열:")
print(ary)

# 1. 전체의 최댓값
print(f"max - {np.max(ary)}")

# 2. 행 합을 열로 추가
row_sum = np.sum(ary, axis=1).reshape(5, 1)
with_row_sum = np.hstack([ary, row_sum])
print("행 합을 열로 추가:")
print(with_row_sum)

# 3. 각 행의 최댓값
print(f"max - {np.max(ary, axis=1)}")

# 4. 각 열의 평균을 행으로 추가
col_mean = np.mean(ary, axis=0).astype('int32').reshape(1, -1)
with_col_mean = np.vstack([ary, col_mean])
print("열 평균을 행으로 추가:")
print(with_col_mean)

# 5. 각 열의 최솟값
print(f"col min  - {np.min(ary, axis=0)}")
```

#### 💻 코드 실행 상세 분석

**1단계 (랜덤 배열 생성)**: `np.random.randint(1, 1000000, (5, 6))`로 5행 6열의 랜덤 정수 배열 생성

**2단계 (행 합 추가)**:
- `np.sum(ary, axis=1)`: 각 행의 합 계산 → `(5,)` 형태
- `.reshape(5, 1)`: `(5, 1)` 형태로 변경하여 열로 만듦
- `np.hstack()`: 원본 배열과 수평으로 결합

**3단계 (열 평균 추가)**:
- `np.mean(ary, axis=0)`: 각 열의 평균 계산 → `(6,)` 형태
- `.astype('int32')`: 정수형으로 변환
- `.reshape(1, -1)`: `(1, 6)` 형태로 변경하여 행으로 만듦
- `np.vstack()`: 원본 배열과 수직으로 결합

**최종 결과**: 원본 배열에 통계 정보가 추가된 확장 배열을 생성할 수 있습니다.

> 📌 **노트**: `hstack()`은 수평(horizontal) 결합, `vstack()`은 수직(vertical) 결합을 수행합니다. 이는 데이터 분석에서 매우 자주 사용되는 패턴입니다.


## 🔄 배열 정렬 (Sorting)

### 📖 정렬의 두 가지 방식

강사님께서는 "정렬은 데이터 시각화에서 매우 중요하다"고 강조하셨습니다. 정렬된 막대 그래프가 더 보기 좋고 인사이트를 찾기 쉽기 때문입니다.

NumPy는 두 가지 정렬 방식을 제공합니다:

1. **np.sort()**: 원본을 변경하지 않고 정렬된 복사본 반환 (In-place = False)
2. **array.sort()**: 원본 배열을 직접 정렬 (In-place = True)

### 🔢 1차원 배열 정렬

```python
# 정렬을 위한 랜덤 배열 생성
np.random.seed(42)  # 결과를 동일하게 보기 위해 시드 고정
sort_arr = np.random.randint(1, 100, 10)
print(f"원본 랜덤 배열: {sort_arr}")

# np.sort(): 원본을 바꾸지 않고 정렬된 '새로운' 배열 반환
sorted_copy = np.sort(sort_arr)
print(f"np.sort() 후 반환된 배열: {sorted_copy}")
print(f"np.sort() 후 원본 배열: {sort_arr} (변경 없음)")

# 내림차순 정렬
print(f"내림차순 정렬: {np.sort(sort_arr)[::-1]}")

# array.sort(): 원본 배열을 '직접' 정렬 (in-place)
sort_arr.sort()
print(f"array.sort() 후 원본 배열: {sort_arr} (변경됨)")
```

**출력 결과**:
```
원본 랜덤 배열: [52 93  2 88 23 16  7 30 64 54]
np.sort() 후 반환된 배열: [ 2  7 16 23 30 52 54 64 88 93]
np.sort() 후 원본 배열: [52 93  2 88 23 16  7 30 64 54] (변경 없음)
내림차순 정렬: [93 88 64 54 52 30 23 16  7  2]
array.sort() 후 원본 배열: [ 2  7 16 23 30 52 54 64 88 93] (변경됨)
```

#### 💻 코드 실행 상세 분석

**np.sort() 방식**

**1단계 (함수 호출)**: `np.sort(sort_arr)` 실행

**2단계 (정렬된 복사본 생성)**: 원본 배열은 그대로 두고, 정렬된 **새로운 배열**을 생성하여 반환합니다.

**3단계 (원본 확인)**: 원본 배열 `sort_arr`는 변경되지 않았습니다.

**최종 결과**: 원본을 보존해야 할 때 사용합니다.


**array.sort() 방식**

**1단계 (메서드 호출)**: `sort_arr.sort()` 실행

**2단계 (원본 수정)**: 원본 배열 자체를 직접 정렬합니다 (in-place 정렬).

**3단계 (반환값)**: `None`을 반환합니다.

**최종 결과**: 메모리 효율적이지만 원본이 손실됩니다.

> 💡 **중요!**: `array.sort()`는 반환값이 `None`입니다. 따라서 `new = ary.sort()` 같은 코드를 작성하면 `new`에는 `None`이 할당됩니다!


### 📉 내림차순 정렬

NumPy에는 직접적인 내림차순 정렬 함수가 없습니다. 대신 **슬라이싱을 역순으로** 사용합니다.

```python
# 내림차순 정렬
descending = np.sort(sort_arr)[::-1]
print(f"내림차순 정렬: {descending}")
```

#### 💻 코드 실행 상세 분석

**1단계 (오름차순 정렬)**: `np.sort(sort_arr)`로 먼저 오름차순 정렬

**2단계 (역순 슬라이싱)**: `[::-1]`를 사용하여 배열을 뒤집습니다.
- `step=-1`은 끝에서 시작으로 이동한다는 의미

**최종 결과**: 내림차순으로 정렬된 배열이 반환됩니다.

> 📌 **노트**: `[::-1]`은 NumPy 배열과 Python 리스트 모두에서 작동하는 역순 슬라이싱 기법입니다.


### 📊 2차원 배열 정렬

2차원 배열에서는 **축(axis)** 지정이 필수입니다.

```python
# 4x4 랜덤 배열 생성
ary = np.random.randint(1, 17, (4, 4))
print("원본 배열:")
print(ary)

# 열에 대한 정렬 (axis=0)
print("열에 대한 정렬 (axis=0):")
print(np.sort(ary, axis=0))

# 행에 대한 정렬 (axis=1)
print("행에 대한 정렬 (axis=1):")
print(np.sort(ary, axis=1))
```

**출력 결과 예시**:
```
원본 배열:
[[ 2  4 11 15]
 [ 9 11  8  7]
 [ 7 13 14 13]
 [ 7  4 13  9]]

열에 대한 정렬 (axis=0):
[[ 2  4  8  7]
 [ 7  4 11  9]
 [ 7 11 13 13]
 [ 9 13 14 15]]

행에 대한 정렬 (axis=1):
[[ 2  4 11 15]
 [ 7  8  9 11]
 [ 7 13 13 14]
 [ 4  7  9 13]]
```

#### 💻 코드 실행 상세 분석

**axis=0 (열 정렬)**

**1단계 (각 열별 정렬)**: 각 열을 독립적으로 정렬합니다.
- 0열 `[2, 9, 7, 7]` → `[2, 7, 7, 9]`
- 1열 `[4, 11, 13, 4]` → `[4, 4, 11, 13]`
- 2열 `[11, 8, 14, 13]` → `[8, 11, 13, 14]`
- 3열 `[15, 7, 13, 9]` → `[7, 9, 13, 15]`

**최종 결과**: 각 열이 수직으로 정렬되며, 행 간의 관계는 유지되지 않습니다.


**axis=1 (행 정렬)**

**1단계 (각 행별 정렬)**: 각 행을 독립적으로 정렬합니다.
- 0행 `[2, 4, 11, 15]` → `[2, 4, 11, 15]` (이미 정렬됨)
- 1행 `[9, 11, 8, 7]` → `[7, 8, 9, 11]`
- 2행 `[7, 13, 14, 13]` → `[7, 13, 13, 14]`
- 3행 `[7, 4, 13, 9]` → `[4, 7, 9, 13]`

**최종 결과**: 각 행이 수평으로 정렬되며, 열 간의 관계는 유지되지 않습니다.

> 💡 **중요!**: 다차원 배열의 정렬은 **데이터의 관계를 깨뜨릴 수 있습니다**. 원본 데이터의 행-열 관계를 유지하면서 정렬하려면 다른 방법(예: Pandas의 sort_values)을 사용해야 합니다.


### 🎯 argsort(): 정렬된 인덱스 반환

강사님께서는 "argsort는 처음에 이해하기 어렵지만, 시각화에서 매우 유용하다"고 강조하셨습니다.

```python
# 간단한 배열로 argsort 이해하기
ary = np.array([4, 3, 5, 7])
print(f"원본 배열: {ary}")

# argsort: 정렬 후의 인덱스를 반환
sorted_indices = np.argsort(ary)
print(f"정렬된 인덱스 (argsort): {sorted_indices}")
print(f"argsort 인덱스를 사용한 정렬: {ary[sorted_indices]}")
```

**출력 결과**:
```
원본 배열: [4 3 5 7]
정렬된 인덱스 (argsort): [1 0 2 3]
argsort 인덱스를 사용한 정렬: [3 4 5 7]
```

#### 💻 코드 실행 상세 분석

**1단계 (argsort 실행)**: `np.argsort(ary)` 호출

**2단계 (정렬 시뮬레이션)**:
- 원본 배열을 정렬하면: `[3, 4, 5, 7]`
- 각 값의 원본 인덱스를 추적:
  - `3`의 원본 인덱스: 1
  - `4`의 원본 인덱스: 0
  - `5`의 원본 인덱스: 2
  - `7`의 원본 인덱스: 3

**3단계 (인덱스 배열 반환)**: `[1, 0, 2, 3]`이 반환됩니다.

**4단계 (팬시 인덱싱)**: `ary[sorted_indices]`를 사용하면 정렬된 배열을 얻을 수 있습니다.
- `ary[1]` → 3
- `ary[0]` → 4
- `ary[2]` → 5
- `ary[3]` → 7

**최종 결과**: `[3, 4, 5, 7]` 정렬된 배열이 반환됩니다.

> 📌 **노트**: `argsort()`의 핵심은 "정렬 전 인덱스"를 기록한다는 것입니다. 이를 통해 정렬된 순서대로 원본 데이터나 관련 데이터에 접근할 수 있습니다.


### 📐 2차원 배열의 argsort

2차원 배열에서 `argsort()`를 사용할 때는 축을 지정해야 합니다.

```python
# 4x4 랜덤 배열 생성
ary = np.random.randint(1, 17, (4, 4))
print("원본 배열:")
print(ary)

# axis=0: 열에 대한 정렬 인덱스
print("열에 대한 정렬 인덱스 (axis=0):")
print(np.argsort(ary, axis=0))
```

**출력 결과 예시**:
```
원본 배열:
[[ 5  4 10 13]
 [11 12 15  5]
 [15 14  8 12]
 [10  5  9 14]]

열에 대한 정렬 인덱스 (axis=0):
[[0 0 2 1]
 [3 3 3 2]
 [1 1 0 0]
 [2 2 1 3]]
```

#### 💻 코드 실행 상세 분석

**axis=0 분석**

강사님께서 강조하신 내용: **"당 열의 행의 인덱스"**를 반환합니다.

**1단계 (0열 분석)**:
- 원본 0열: `[5, 11, 15, 10]`
- 정렬하면: `[5, 10, 11, 15]`
- 정렬 순서의 원본 인덱스: `[0, 3, 1, 2]`

**2단계 (1열 분석)**:
- 원본 1열: `[4, 12, 14, 5]`
- 정렬하면: `[4, 5, 12, 14]`
- 정렬 순서의 원본 인덱스: `[0, 3, 1, 2]`

**최종 결과**: 각 열에 대해, 작은 값부터 큰 값 순서로 **행 인덱스**를 반환합니다.

> 💡 **중요!**: 강사님 설명대로, `axis=0`일 때는 "각 열 내에서 행의 순서"를, `axis=1`일 때는 "각 행 내에서 열의 순서"를 반환합니다.

**실전 활용 예제**:

```python
# 내림차순으로 정렬하기
print(f"내림차순: {ary[sorted_indices][::-1]}")
```

이처럼 `argsort()`는 정렬 인덱스를 활용한 다양한 응용이 가능합니다.


## 🌐 브로드캐스팅 (Broadcasting)

### 📖 브로드캐스팅이란?

강사님께서는 수업 마지막에 "벡터화 연산을 설명하면서 빼먹은 중요한 개념"이라며 **브로드캐스팅(Broadcasting)**을 추가로 설명하셨습니다.

**브로드캐스팅**은 크기가 다른 배열 간의 연산을 가능하게 하는 NumPy의 강력한 기능입니다.

### 🔢 스칼라와 배열의 연산

일반적으로 크기가 다른 두 배열은 연산할 수 없습니다. 하지만 NumPy는 자동으로 작은 배열을 확장하여 연산을 가능하게 합니다.

```python
# 벡터와 스칼라의 연산
x = np.arange(10)
print(f"원본 배열: {x}")

# 스칼라 연산
result = x + 100
print(f"x + 100: {result}")
```

**출력 결과**:
```
원본 배열: [0 1 2 3 4 5 6 7 8 9]
x + 100: [100 101 102 103 104 105 106 107 108 109]
```

#### 💻 코드 실행 상세 분석

**1단계 (크기 불일치 감지)**: `x`는 10개 요소의 배열, `100`은 스칼라 (크기 1)

**2단계 (브로드캐스팅)**: NumPy가 `100`을 `[100, 100, ..., 100]` (10개)로 자동 확장

**3단계 (요소별 덧셈)**: 확장된 배열과 원본 배열을 요소별로 더합니다.
- `x[0] + 100` = 0 + 100 = 100
- `x[1] + 100` = 1 + 100 = 101
- ...

**최종 결과**: 모든 요소에 100이 더해진 `[100, 101, ..., 109]`가 반환됩니다.


### 📐 배열과 리스트의 브로드캐스팅

```python
# 2차원 배열과 1차원 리스트의 연산
arr_2d = np.arange(12).reshape(3, 4)
print("원본 2차원 배열:")
print(arr_2d)

# 리스트와의 브로드캐스팅
result = arr_2d + [100, 200, 300, 400]
print("브로드캐스팅 결과:")
print(result)
```

**출력 결과**:
```
원본 2차원 배열:
[[ 0  1  2  3]
 [ 4  5  6  7]
 [ 8  9 10 11]]

브로드캐스팅 결과:
[[100 201 302 403]
 [104 205 306 407]
 [108 209 310 411]]
```

#### 💻 코드 실행 상세 분석

**1단계 (크기 분석)**:
- `arr_2d`: `(3, 4)` 형태
- `[100, 200, 300, 400]`: `(4,)` 형태

**2단계 (브로드캐스팅 규칙)**:
- 리스트를 `(1, 4)` 형태로 해석
- 이를 `(3, 4)` 형태로 확장: `[[100, 200, 300, 400], [100, 200, 300, 400], [100, 200, 300, 400]]`

**3단계 (요소별 덧셈)**:
- 0행: `[0, 1, 2, 3] + [100, 200, 300, 400]` = `[100, 201, 302, 403]`
- 1행: `[4, 5, 6, 7] + [100, 200, 300, 400]` = `[104, 205, 306, 407]`
- 2행: `[8, 9, 10, 11] + [100, 200, 300, 400]` = `[108, 209, 310, 411]`

**최종 결과**: 각 행에 리스트의 값들이 열별로 더해집니다.

> 💡 **중요!**: 브로드캐스팅의 핵심은 **자동으로 배열을 확장하여 크기를 맞춘다**는 것입니다. 이는 선형대수의 수식을 그대로 코드로 작성할 수 있게 해주는 강력한 기능입니다.


### 📏 브로드캐스팅 규칙

NumPy의 브로드캐스팅은 다음 규칙을 따릅니다:

1. **차원 맞추기**: 두 배열의 차원이 다르면, 차원이 작은 배열의 앞쪽에 1을 추가
2. **크기 확인**: 각 차원에서 크기가 같거나, 둘 중 하나가 1이어야 함
3. **크기 1인 차원 확장**: 크기가 1인 차원을 다른 배열의 크기로 확장

**예제**:
- `(3, 4)` + `(4,)` → `(4,)`를 `(1, 4)`로 해석 → `(3, 4)`로 확장 ✅
- `(3, 4)` + `(3, 1)` → `(3, 1)`을 `(3, 4)`로 확장 ✅
- `(3, 4)` + `(3,)` → 불가능 (열 개수 불일치) ❌

> 📌 **노트**: 브로드캐스팅이 실패하면 `ValueError: operands could not be broadcast together` 에러가 발생합니다.


## 🔐 보안 노트: NumPy의 보안 취약점

### ⚠️ pickle 직렬화의 위험성

강사님께서는 강의 중에는 언급하지 않으셨지만, Python 코드에 중요한 보안 내용이 포함되어 있었습니다.

NumPy는 배열을 파일로 저장할 때 `pickle` 프로토콜을 사용합니다. **pickle은 악의적인 코드를 포함할 수 있어 매우 위험합니다.**

### 🚨 악의적인 pickle 예제

```python
import os
import numpy as np

# 악의적인 pickle 데이터를 포함할 수 있는 클래스
class Malicious:
    def __reduce__(self):
        # 실제 악성코드는 시스템 명령을 실행할 수 있음
        # 예: os.system("rm -rf /")
        return (print, ("악성 코드가 실행될 수 있습니다!",))

malicious_data = np.array([Malicious()], dtype=object)

# 위험한 파일 저장 (allow_pickle=True)
try:
    np.save("malicious.npy", malicious_data)
except Exception as e:
    print(f"np.save 에러: {e}")
```

#### 💻 코드 실행 상세 분석

**1단계 (악의적인 클래스 정의)**: `Malicious` 클래스는 `__reduce__()` 메서드를 오버라이드합니다.

**2단계 (`__reduce__`의 역할)**: pickle이 객체를 직렬화할 때 호출되는 메서드입니다. 이 메서드가 반환하는 함수가 역직렬화 시 실행됩니다.

**3단계 (잠재적 위험)**: 실제 공격자는 `os.system()`으로 시스템 명령을 실행하거나, 파일을 삭제하거나, 백도어를 설치할 수 있습니다.

**최종 결과**: pickle은 **임의의 Python 코드를 실행**할 수 있으므로, 신뢰할 수 없는 소스의 pickle 파일은 절대 로드하면 안 됩니다.


### ✅ 안전한 NumPy 파일 로드

```python
# 안전하지 않은 로드 (allow_pickle=True) - 기본값
print("--- 안전하지 않은 로드 (allow_pickle=True) ---")
try:
    loaded_data = np.load("malicious.npy", allow_pickle=True)
    print("파일 로드 성공 (위험).")
except ValueError as e:
    print(f"np.load 에러: {e}")

# 안전한 로드 (allow_pickle=False)
print("\n--- 안전한 로드 (allow_pickle=False) ---")
try:
    loaded_data_safe = np.load("malicious.npy", allow_pickle=False)
except ValueError as e:
    print(f"np.load 에러 (안전): {e}")
finally:
    # 생성된 파일 정리
    if os.path.exists("malicious.npy"):
        os.remove("malicious.npy")
```

**출력 결과**:
```
--- 안전하지 않은 로드 (allow_pickle=True) ---
악성 코드가 실행될 수 있습니다!
파일 로드 성공 (위험).

--- 안전한 로드 (allow_pickle=False) ---
np.load 에러 (안전): Object arrays cannot be loaded when allow_pickle=False
```

#### 💻 코드 실행 상세 분석

**안전하지 않은 로드 (`allow_pickle=True`)**

**1단계 (파일 로드)**: `np.load("malicious.npy", allow_pickle=True)` 실행

**2단계 (역직렬화)**: pickle이 `Malicious` 객체를 복원하면서 `__reduce__()` 메서드가 반환한 함수를 실행합니다.

**3단계 (코드 실행)**: `print("악성 코드가 실행될 수 있습니다!")`가 즉시 실행됩니다.

**최종 결과**: 파일을 로드하는 것만으로 악의적인 코드가 실행될 수 있습니다.


**안전한 로드 (`allow_pickle=False`)**

**1단계 (파일 로드 시도)**: `np.load("malicious.npy", allow_pickle=False)` 실행

**2단계 (검증)**: NumPy가 파일에 객체(object) 타입이 포함되어 있음을 감지

**3단계 (에러 발생)**: `ValueError: Object arrays cannot be loaded when allow_pickle=False` 발생

**최종 결과**: 파일 로드가 차단되어 악성 코드가 실행되지 않습니다.

> 🔐 **보안 권장사항**:
> 1. **항상 `allow_pickle=False` 사용**: 신뢰할 수 없는 소스의 `.npy`, `.npz` 파일을 로드할 때는 반드시 `allow_pickle=False`를 설정하세요.
> 2. **입력 검증**: 파일의 출처를 확인하고, 신뢰할 수 있는 소스에서만 파일을 로드하세요.
> 3. **대안 사용**: 가능하다면 텍스트 기반 포맷(CSV, JSON)이나 HDF5 같은 더 안전한 포맷을 사용하세요.
> 4. **샌드박스 환경**: 신뢰할 수 없는 파일을 로드해야 한다면, 격리된 환경(Docker 컨테이너 등)에서 실행하세요.


## 🧩 복합 및 심화 예제: 서버 로그 분석 시스템

### 📖 실전 시나리오

실제 데이터 분석 상황을 시뮬레이션하는 복합 예제입니다. 서버 로그 데이터를 NumPy 배열로 처리하고, 심각도가 높은 로그를 필터링하여 분석한 후, 그 결과를 JSON으로 변환하여 AI 서비스에 전달하는 전체 워크플로우를 구현합니다.

### 1️⃣ 데이터 준비: 서버 로그 시뮬레이션

```python
import json
import numpy as np

# 각 행: [timestamp, status_code, response_time_ms, severity]
# severity: 0=INFO, 1=WARN, 2=ERROR, 3=CRITICAL
log_data = np.array([
    [1672531201, 200, 150, 0],
    [1672531202, 503, 2500, 3],
    [1672531203, 200, 200, 0],
    [1672531204, 404, 50, 1],
    [1672531205, 500, 1800, 2],
    [1672531206, 200, 120, 0],
    [1672531207, 503, 3000, 3],
])
print("--- 원본 로그 데이터 (NumPy 배열) ---")
print(log_data)
```

**출력 결과**:
```
--- 원본 로그 데이터 (NumPy 배열) ---
[[1672531201     200     150       0]
 [1672531202     503    2500       3]
 [1672531203     200     200       0]
 [1672531204     404      50       1]
 [1672531205     500    1800       2]
 [1672531206     200     120       0]
 [1672531207     503    3000       3]]
```

#### 💻 코드 실행 상세 분석

**1단계 (2차원 배열 생성)**: 7개의 로그 엔트리, 각 엔트리는 4개의 필드를 가집니다.

**2단계 (필드 의미)**:
- 열 0: 타임스탬프 (Unix timestamp)
- 열 1: HTTP 상태 코드
- 열 2: 응답 시간 (밀리초)
- 열 3: 심각도 레벨 (0=INFO, 1=WARN, 2=ERROR, 3=CRITICAL)

**최종 결과**: 실제 서버 로그를 표현하는 구조화된 데이터가 준비되었습니다.


### 2️⃣ 데이터 분석 함수: CRITICAL 로그 필터링

```python
def analyze_critical_logs(logs):
    """심각도 'CRITICAL'(3)인 로그를 필터링하고 분석하는 함수"""
    # 불리언 마스킹으로 심각도가 3인 로그만 추출
    critical_mask = logs[:, 3] == 3
    critical_logs = logs[critical_mask]

    if critical_logs.shape[0] > 0:
        # 평균 응답 시간 계산
        avg_response_time = np.mean(critical_logs[:, 2])
        # 발생 횟수
        count = critical_logs.shape[0]
        
        analysis = {
            "level": "CRITICAL",
            "count": count,
            "avg_response_time_ms": round(avg_response_time, 2),
            "timestamps": critical_logs[:, 0].tolist()
        }
        return analysis
    else:
        return {"level": "CRITICAL", "count": 0}

critical_analysis = analyze_critical_logs(log_data)
print("\n--- 심각도 'CRITICAL' 분석 결과 ---")
print(critical_analysis)
```

**출력 결과**:
```
--- 심각도 'CRITICAL' 분석 결과 ---
{'level': 'CRITICAL', 'count': 2, 'avg_response_time_ms': 2750.0, 'timestamps': [1672531202, 1672531207]}
```

#### 💻 코드 실행 상세 분석

**1단계 (불리언 마스킹)**:
- `logs[:, 3] == 3`: 4번째 열(심각도)이 3인지 확인
- 결과: `[False, True, False, False, False, False, True]`

**2단계 (필터링)**:
- `critical_logs = logs[critical_mask]`: CRITICAL 레벨의 로그만 선택
- 결과: 2개의 행만 남음

**3단계 (통계 계산)**:
- 발생 횟수: `critical_logs.shape[0]` = 2
- 평균 응답 시간: `np.mean(critical_logs[:, 2])` = (2500 + 3000) / 2 = 2750.0

**4단계 (타임스탬프 추출)**:
- `critical_logs[:, 0].tolist()`: 0번째 열(타임스탬프)을 리스트로 변환
- 결과: `[1672531202, 1672531207]`

**최종 결과**: CRITICAL 로그에 대한 종합 분석 결과가 딕셔너리 형태로 반환됩니다.


### 3️⃣ AI 연동 시뮬레이션

#### Step 1: AI 요청 페이로드 생성

```python
# 분석된 데이터를 JSON으로 변환하여 AI에 요청
ai_request_payload = json.dumps(critical_analysis, indent=2)
print("\n--- AI 요청 페이로드 (JSON) ---")
print(ai_request_payload)
```

**출력 결과**:
```
--- AI 요청 페이로드 (JSON) ---
{
  "level": "CRITICAL",
  "count": 2,
  "avg_response_time_ms": 2750.0,
  "timestamps": [
    1672531202,
    1672531207
  ]
}
```

#### 💻 코드 실행 상세 분석

**1단계 (JSON 직렬화)**: `json.dumps()`로 Python 딕셔너리를 JSON 문자열로 변환

**2단계 (들여쓰기)**: `indent=2`로 가독성 있는 형식 지정

**최종 결과**: AI 서비스 API에 전송할 수 있는 JSON 페이로드가 생성됩니다.


#### Step 2: AI 응답 수신 (시뮬레이션)

```python
# AI가 분석 결과를 JSON으로 응답했다고 가정
ai_response_json = '''
{
  "incident_id": "INC-2023-11-04-001",
  "summary": "Multiple service unavailable (503) errors detected with high response times.",
  "risk_level": "High",
  "recommended_actions": [
    "1. Check health of upstream service 'auth-service'.",
    "2. Scale up 'web-api' deployment.",
    "3. Notify on-call engineer."
  ],
  "related_metrics": {
    "cpu_usage_peak": "95%",
    "memory_usage_peak": "88%"
  }
}
'''
print("\n--- AI 응답 (JSON) ---")
print(ai_response_json)
```

#### 💻 코드 실행 상세 분석

**1단계 (AI 응답 시뮬레이션)**: 실제 AI 서비스가 반환할 법한 구조화된 JSON 응답을 정의합니다.

**2단계 (응답 구조)**:
- `incident_id`: 인시던트 고유 ID
- `summary`: 문제 요약
- `risk_level`: 위험도 평가
- `recommended_actions`: 권장 조치 사항 리스트
- `related_metrics`: 관련 메트릭 정보

**최종 결과**: AI가 로그 데이터를 분석하여 생성한 인시던트 보고서가 JSON 형식으로 제공됩니다.


#### Step 3: AI 응답 파싱 및 후속 처리

```python
# AI의 JSON 응답을 파싱하여 후속 처리
incident_report = json.loads(ai_response_json)
print("\n--- 파싱된 AI 응답에서 후속 조치 실행 ---")
print(f"위험도: {incident_report['risk_level']}")
print("추천 조치:")
for action in incident_report['recommended_actions']:
    print(f"- {action}")
```

**출력 결과**:
```
--- 파싱된 AI 응답에서 후속 조치 실행 ---
위험도: High
추천 조치:
- 1. Check health of upstream service 'auth-service'.
- 2. Scale up 'web-api' deployment.
- 3. Notify on-call engineer.
```

#### 💻 코드 실행 상세 분석

**1단계 (JSON 파싱)**: `json.loads()`로 JSON 문자열을 Python 딕셔너리로 변환

**2단계 (위험도 출력)**: `incident_report['risk_level']`로 위험도 정보 추출

**3단계 (권장 조치 순회)**: `for` 루프로 권장 조치 리스트를 순회하며 출력

**최종 결과**: AI의 분석 결과를 사람이 읽기 쉬운 형태로 출력하거나, 자동화된 조치를 트리거할 수 있습니다.

> 🧩 **실전 활용**: 이 패턴은 실제 DevOps, SRE(Site Reliability Engineering) 환경에서 로그 모니터링 및 인시던트 대응 자동화에 그대로 적용할 수 있습니다.


## 📚 오늘 배운 내용 총정리

### ✅ 핵심 개념 체크리스트

1. **NumPy의 필요성**
   - Python 리스트의 한계 (속도, 메모리)
   - 배열의 특징 (동일 자료형, 고정 크기)
   - 인공지능에서 배열이 사용되는 이유

2. **배열의 기본 속성**
   - `shape`: 배열의 형태 (행, 열)
   - `ndim`: 배열의 차원
   - `dtype`: 요소의 자료형

3. **벡터화 연산**
   - 반복문 없이 모든 요소에 연산 적용
   - C 언어 기반 최적화로 빠른 성능
   - 산술, 비교, 논리 연산 모두 지원

4. **불리언 마스킹**
   - 조건에 맞는 데이터 필터링
   - SQL의 WHERE 절과 유사한 역할

5. **팬시 인덱싱**
   - 정수 인덱싱: 특정 인덱스들만 선택
   - 불리언 인덱싱: 조건으로 선택

6. **통계 함수**
   - `sum`, `mean`, `max`, `min`
   - `axis` 매개변수: 0=열, 1=행

7. **정렬**
   - `np.sort()`: 복사본 반환
   - `array.sort()`: 원본 수정
   - `argsort()`: 정렬된 인덱스 반환

8. **브로드캐스팅**
   - 크기가 다른 배열 간 연산
   - 자동 배열 확장

9. **보안 고려사항**
   - pickle의 위험성
   - `allow_pickle=False` 사용 권장


### 🎓 강사님의 당부 말씀

강사님께서는 다음과 같이 강조하셨습니다:

> "NumPy 자체를 완벽하게 마스터할 필요는 없습니다. 중요한 것은 **배열의 개념**, **벡터화 연산**, 그리고 **축(axis)의 방향**입니다. 이 세 가지만 확실히 이해하시면 Pandas와 인공지능 라이브러리를 배울 때 훨씬 수월합니다."

또한, "장기 레이스"라는 표현을 사용하시며, 동료들과 함께 꾸준히 학습하는 것의 중요성을 강조하셨습니다.


### 📅 다음 강의 예고

내일(11/4) 강의에서는:

1. **Pandas 기초**: NumPy 배열을 기반으로 한 DataFrame 다루기
2. **탐색적 데이터 분석(EDA)**: 실제 데이터셋으로 인사이트 찾기
3. **데이터 시각화**: Matplotlib을 이용한 그래프 생성

이번 주 후반에는:
- **Streamlit**: 웹 대시보드 만들기
- **VS Code 연동**: Anaconda 인터프리터 설정
- **LLM 기초 개념**: 인공지능 이론 소개


### 🔗 참고 자료

- NumPy 공식 문서: https://numpy.org/doc/
- NumPy 튜토리얼: https://numpy.org/learn/
- 데이터 분석 공부 커뮤니티: Kaggle, Dacon


### 💪 실습 과제 (자율 학습용)

1. **기본 연습**: 
   - 10x10 랜덤 배열을 생성하고, 50보다 큰 값만 필터링하기
   - 각 행과 열의 평균, 최댓값, 최솟값 계산하기

2. **응용 연습**:
   - 학생 5명의 과목 3개 점수를 2차원 배열로 표현
   - 각 학생의 평균 점수와 각 과목의 평균 점수 계산
   - 평균이 가장 높은 학생과 가장 낮은 과목 찾기

3. **심화 연습**:
   - 실제 CSV 파일을 `np.loadtxt()`로 읽어오기
   - 데이터 전처리 (결측치 처리, 정규화 등) 수행하기
   - 분석 결과를 JSON으로 저장하기


## 🎉 수고하셨습니다!

오늘 강의에서 NumPy의 핵심 개념들을 모두 학습했습니다. 처음에는 낯설고 어려울 수 있지만, 반복 학습과 실습을 통해 충분히 익숙해질 수 있습니다.

**"한 걸음 한 걸음 우직하게 내딛는다"**는 강사님의 말씀처럼, 꾸준히 학습하시기 바랍니다. 

내일 Pandas 강의에서 뵙겠습니다! 🚀


> **작성자 노트**: 이 강의 노트는 2025년 11월 3일 강의를 바탕으로 작성되었으며, 강사님의 설명과 코드 예제를 최대한 상세하게 담았습니다. 복습 시에는 코드를 직접 실행해보며 결과를 확인하는 것을 권장합니다.