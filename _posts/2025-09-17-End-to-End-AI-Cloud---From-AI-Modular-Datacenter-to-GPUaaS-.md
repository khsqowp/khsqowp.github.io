--- 
title: "Alice의 End-to-End AI 클라우드: 모듈러 데이터센터에서 GPUaaS까지"
date: 2025-09-17
excerpt: "급변하는 GPU 기술 주기에 대응하기 위해 모듈형 데이터센터(PMDC)와 자체 IaaS/PaaS를 수직 통합하여 구축 속도를 획기적으로 단축한 사례를 공유합니다."
categories:
  - Archive
  - conference
  - Dell
tags:
  - conference
  - Dell
  - Archive
---

# End-to-End AI Cloud: AI 모듈러 데이터센터부터 GPUaaS까지

**발표자:** Alice (엘리스)

## 서론: AI 시대의 딜레마 - 인프라 구축 속도가 기술 발전을 따라가지 못하다

AI 기술, 특히 GPU의 발전 속도는 상상을 초월합니다. 1~2년마다 이전 세대를 압도하는 성능과 전력 소비, 그리고 완전히 다른 냉각 방식을 요구하는 새로운 GPU가 등장합니다. 하지만 전통적인 데이터센터를 설계하고, 인허가를 받고, 건설하는 데에는 최소 2~3년이 소요됩니다. 이는 A100 GPU에 최적화된 데이터센터를 짓기 시작하면, 완공 시점에는 이미 수랭 방식이 필수적인 B200 GPU가 시장의 주류가 되어버리는, 즉 **'완공과 동시에 낙후되는'** 심각한 문제에 직면하게 됨을 의미합니다.

Alice는 이러한 AI 인프라 구축의 근본적인 딜레마를 해결하기 위해, 물리적인 데이터센터부터 최종 서비스 플랫폼(GPUaaS)까지 모든 것을 수직적으로 통합한 **'End-to-End AI 클라우드'** 솔루션을 개발했습니다. 이 솔루션의 핵심 목표는 단 하나, **12~16주**라는 압도적인 속도로 최신 AI 인프라를 제공하는 것입니다.

## 계층 1: 물리적 기반 - AI PMDC (Portable Modular Data Center)

Alice 솔루션의 가장 근간이 되는 것은 **AI PMDC**라는 혁신적인 하드웨어 인프라입니다. 이는 기존의 거대하고 고정된 건물 형태의 데이터센터가 아닌, 이동과 확장이 용이한 컨테이너 기반의 모듈형 데이터센터입니다.

*   **핵심 개념:** 표준 40피트 컨테이너 내부에 IT 랙, UPS, 항온항습기, 수랭/공랭 냉각 설비, 관제 시스템(FMS) 등 데이터센터 운영에 필요한 모든 것이 사전에 통합된 All-in-One 솔루션입니다.
*   **신속한 배포:** 표준화된 모듈을 공장에서 제작하여 현장에 설치하므로, 전체 구축 기간을 **3개월** 이내로 단축합니다.
*   **유연성 및 고밀도 지원:** 워크로드의 특성에 맞춰 내부 구성을 완벽하게 맞춤화할 수 있습니다. 추론 서비스를 위한 저밀도 공랭식 컨테이너부터, 대규모 학습을 위한 **랙당 80kW 이상의 고밀도 수랭식(DLC) B200 컨테이너**까지 다양한 구성이 가능합니다.
*   **대규모 클러스터링 최적화:** PMDC의 가장 큰 장점 중 하나는 대규모 클러스터 구축 시 나타납니다. 수천 개의 GPU를 저지연 인피니밴드(InfiniBand)로 연결할 때, 케이블 길이는 성능에 치명적입니다. 평면적인 일반 데이터센터와 달리, PMDC는 **컨테이너를 3차원으로 쌓고 배치**하여 GPU 간의 물리적 거리를 최적화하고, 가장 짧은 케이블 경로를 확보할 수 있습니다. 이를 통해 케이블 길이를 30m 이내로 유지하여, 지연 시간(Latency)을 최소화한 고성능 클러스터 구축이 가능합니다.

## 계층 2: 제어 시스템 - ECI (Alice Cloud Infrastructure)

물리적 인프라 위에는 이를 가상화하고 제어하는 클라우드 플랫폼(IaaS)이 필요합니다. Alice는 OpenStack이나 VMware와 같은 범용 IaaS 대신, AI 워크로드에만 집중하는 자체 경량 IaaS인 **ECI**를 개발했습니다.

*   **개발 이유:** 범용 IaaS는 수백 개의 불필요한 기능으로 인해 무겁고, 유지보수 비용이 높습니다. Alice는 AI 학습 및 추론에 필요한 핵심 기능(컴퓨팅, 스토리지, 네트워크 관리)만을 담아, 가볍고 효율적이며 관리가 용이한 제어 시스템을 만들었습니다.
*   **핵심 기능 - 하드웨어 토폴로지 인지 스케줄러:** ECI의 가장 큰 특징은 물리적 하드웨어의 구조(어떤 GPU가 어떤 PCIe 스위치 아래에 있는지 등)를 완벽하게 인지하고, 이에 맞춰 가상머신(VM)을 할당하는 지능형 스케줄러입니다. 
    *   **학습 워크로드:** 여러 개의 GPU를 요청하면, 스케줄러는 가장 낮은 지연 시간으로 통신할 수 있도록 **물리적으로 가장 인접한 GPU들을 묶어** 할당합니다.
    *   **추론 워크로드:** 높은 가용성이 중요하므로, 여러 PMDC에 **자원을 분산 배치**하여 하나의 인프라에 장애가 발생해도 서비스가 중단되지 않도록 합니다.

## 계층 3: 사용자 플랫폼 - 개발자 중심의 GPUaaS

Alice는 인프라의 복잡성을 완전히 추상화하고, AI 연구자와 개발자가 오직 자신의 모델에만 집중할 수 있도록 설계된 3가지 핵심 서비스를 제공합니다.

1.  **데이터 허브:** AI 모델 학습에 필요한 대용량 원시 데이터셋과, 학습 과정에서 생성되는 수많은 버전의 모델 체크포인트(Checkpoint)를 안전하고 효율적으로 저장하기 위한 **S3 호환 오브젝트 스토리지**입니다.
2.  **온디맨드 AI 워크벤치:** AI 개발에 필요한 프레임워크와 라이브러리가 모두 설치된 개발 환경을 **단 한 번의 클릭으로 2분 안에 생성**해주는 서비스입니다. 생성된 환경은 데이터 허브와 자동으로 연동되어, 데이터 이동이나 설정의 번거로움 없이 즉시 모델 개발을 시작할 수 있습니다.
3.  **AI 모델 서빙:** 개발이 완료된 모델 파일을 업로드하기만 하면, 확장성, 인증, 모니터링 기능이 모두 포함된 **REST API 엔드포인트를 자동으로 생성**해주는 서버리스(Serverless) 형태의 서비스입니다.

## 결론: 수직적 통합을 통한 AI 인프라 혁신

Alice의 End-to-End AI 클라우드는 데이터센터 부지 선정부터 최종 AI 서비스 배포까지, 파편화되어 있던 모든 과정을 수직적으로 통합한 혁신적인 솔루션입니다. 이 통합된 접근 방식은 기존 방식 대비 명확한 이점을 제공합니다.

*   **압도적인 속도:** 전체 시스템 구축까지 **12~16주**라는, 기존과 비교할 수 없는 속도를 자랑합니다.
*   **TCO 절감:** 모듈러 데이터센터와 경량 IaaS를 통해, 5년 운영 기준으로 TCO를 **약 50% 절감**할 수 있습니다.
*   **통합 SLA 및 보안:** 전 계층을 직접 제어하므로, 더 높은 수준의 서비스수준협약(SLA)을 보장하고, CSAP와 같은 보안 인증 대응이 용이합니다.

Alice는 단순한 서비스 제공업체를 넘어, 고객의 요구에 맞춰 최신 기술이 적용된 AI 클라우드 전체를 턴키(Turnkey)로 구축해주는 솔루션 파트너로서, AI 시대의 인프라 구축 패러다임을 새롭게 정의하고 있습니다.
