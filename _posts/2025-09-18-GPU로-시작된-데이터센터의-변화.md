--- 
title: "GPU로 시작된 데이터센터의 변화: NHN Cloud의 현재와 미래"
date: 2025-09-18
excerpt: "**발표자:** 윤용수, NHN Cloud    NHN Cloud는 GPU가 데이터센터의 핵심으로 떠오르기 훨씬 이전부터 고밀도, 고발열 환경을 다루는 데 깊은 노하우를 축적해왔습니다. 게임, 결제 등 대규모 트래픽을 처리하는 서비스의 특성상, 한정된 공간에 최대한 많은 컴퓨팅 자원을 집적하고 안정적으로 운영하는 것이 필수적이었습니다. 이러한 경험은 NHN..."
categories:
  - Archive
  - conference
  - DIC 2025
tags:
  - DIC 2025
  - conference
  - Archive
---

# GPU로 시작된 데이터센터의 변화: NHN Cloud의 현재와 미래

**발표자:** 윤용수, NHN Cloud

## 서론: 고밀도 데이터센터 운영의 숨은 강자, NHN Cloud

NHN Cloud는 GPU가 데이터센터의 핵심으로 떠오르기 훨씬 이전부터 고밀도, 고발열 환경을 다루는 데 깊은 노하우를 축적해왔습니다. 게임, 결제 등 대규모 트래픽을 처리하는 서비스의 특성상, 한정된 공간에 최대한 많은 컴퓨팅 자원을 집적하고 안정적으로 운영하는 것이 필수적이었습니다. 이러한 경험은 NHN Cloud를 GPU 시대의 주역으로 이끄는 강력한 자산이 되었습니다.

*   **시대를 앞서간 기술력:** 2015년, 국내 데이터센터의 랙당 평균 전력이 4.4kW 수준일 때, NHN Cloud는 이미 **8kW급 고밀도 데이터센터**를 구축하고 10년 가까이 안정적으로 운영해왔습니다. 또한, 당시 글로벌 평균 PUE(전력사용효율)가 1.5 수준일 때, 외기 냉방 기술 등을 적극 활용하여 **PUE 1.3**을 달성하는 등 에너지 효율 측면에서도 선도적인 역량을 보유하고 있었습니다.

본 발표는 NHN Cloud가 이러한 기술적 배경을 바탕으로 어떻게 국가 AI 데이터센터의 핵심 사업자로 부상했으며, GPU가 데이터센터 산업 전체를 어떻게 바꾸고 있는지에 대한 통찰을 공유합니다.

## 본론 1: 광주 AI 데이터센터 - 국가 GPU 인프라의 초석을 놓다

NHN Cloud의 검증된 고밀도 데이터센터 운영 역량은 국내 최초의 GPU 전용 데이터센터인 **광주 국가 AI 데이터센터** 구축 및 운영 사업을 수주하는 결정적인 계기가 되었습니다. NHN Cloud는 이 프로젝트에서 단순 운영을 넘어, 데이터센터의 건축 설계부터 핵심 기반 설비 구축, AI 컴퓨팅 자원 도입 및 운영까지 전 과정을 주도했습니다.

*   **혁신적인 공랭 기술의 집약:** 광주 센터는 랙당 **15kW**의 전력을 안정적으로 공급하도록 설계되었으며, 특정 구역은 최대 **45kW**까지 수용 가능합니다. 이는 기존의 이중마루(Raised Floor) 하부 공조 방식을 탈피하고, ▲천장고를 8m까지 높여 충분한 공기 순환 공간 확보 ▲강력한 풍량 설계(기준치 대비 1.8배) ▲양방향에서 냉기를 불어넣는 **사이드 블로잉(Side-blowing)** 냉각 방식 등 NHN Cloud만의 독자적인 공랭 기술을 적용했기에 가능했습니다.
*   **국내 최대 GPU 클러스터 구축:** 2023년 개소 당시, 광주 AI 데이터센터는 NVIDIA GPU와 국산 사피온(SAPEON) 반도체를 포함한 멀티 GPU 팜을 구성하여, 총 **100페타플롭스(PetaFLOPS)**에 가까운 연산 능력을 갖춘 국내 최대 규모의 AI 인프라였습니다.

이 프로젝트의 성공적인 수행은 NHN Cloud가 차세대 AI 인프라 시장을 이끌어갈 핵심 플레이어임을 증명하는 계기가 되었습니다.

## 본론 2: 차세대 국가 GPU 사업 - B200과 수랭 기술의 전면 도입

광주에서의 성공을 발판으로, NHN Cloud는 후속 국가 주도 GPU 확보 사업에서 최다 구축 사업자로 선정되었습니다. 이 과정에서 NHN Cloud는 시장의 변화를 정확히 읽고 과감한 제안을 했습니다.

1.  **최신 GPU 전면 도입:** GPU의 발전 속도가 매우 빠르다는 점을 고려, H100/H200이 아닌 NVIDIA의 최신 아키텍처인 **B200 GPU 7,600장**을 전량 도입하여, 사용자에게 가장 강력하고 효율적인 컴퓨팅 파워를 제공할 것을 제안했습니다.
2.  **수랭(Liquid Cooling) 방식의 채택:** 칩 하나당 발열량이 1,200W에 달하는 B200은 더 이상 공랭으로 감당하기 어렵다는 판단 아래, GPU와 CPU를 모두 물로 식히는 **직접 수랭(Direct Liquid Cooling, DLC)** 방식을 전면 채택했습니다. 이는 공랭 방식에 대한 깊은 이해가 있었기에 내릴 수 있는 결정이었습니다.

이 새로운 클러스터는 총 **570페타플롭스** 이상의 연산 규모를 갖추게 되며, 가장 큰 단일 클러스터는 TOP500 슈퍼컴퓨터 리스트의 50위권 내 진입을 목표로 하고 있습니다. 수랭 방식의 도입은 ▲서버 팬 제거로 인한 IT 장비 전력 소모 15% 이상 절감 ▲소음 문제 해결(105dB 이상 → 일상 수준) ▲GPU 안정성 및 수명 향상 ▲고밀도 집적을 통한 공간 효율 극대화 등 데이터센터 운영의 패러다임을 바꾸는 혁신을 가져올 것입니다.

## 본론 3: 글로벌 트렌드의 변화 - '데이터센터'에서 'AI 팩토리'로

MS, 메타, 구글 등 글로벌 빅테크들은 AI 인프라에 수천억 달러에 달하는 천문학적인 금액을 투자하고 있습니다. 이들의 움직임에서 나타나는 두 가지 핵심 키워드는 **'속도'**와 **'규모'**입니다.

*   **메타의 '텐트형' 데이터센터:** 전통적인 건물 건설 방식의 한계를 극복하고 신속하게 인프라를 구축하기 위해, 조립식 초경량 구조물을 사용하고 심지어 일부 시설에서는 백업 전력 시스템을 생략하는 등 기존의 상식을 파괴하는 시도를 하고 있습니다.
*   **NVIDIA의 'AI 팩토리' 청사진:** 마치 공장에서 제품을 찍어내듯, 표준화된 모듈을 반복적으로 건설하여 1GW급의 거대한 캠퍼스를 조성하는 청사진을 제시하고 있습니다.

이러한 움직임은 '데이터센터'라는 명칭을 **'AI 팩토리(AI Factory)'**로 바꾸고 있습니다. 이는 단순히 이름의 변화가 아니라, AI 인프라를 바라보는 관점의 근본적인 전환을 의미합니다. 즉, AI 모델을 생산하는 '공장'이라는 개념을 도입함으로써, 건설 속도를 높이고, 규모의 경제를 실현하며, 데이터센터에 대한 부정적인 인식을 희석하고 산업 시설로서의 혜택을 추구하려는 전략적 의도가 담겨 있습니다.

## 결론: GPU 시대, '소유'에서 '서비스'로의 전환

GPU로 시작된 변화는 데이터센터의 모든 것을 바꾸고 있습니다. 수랭 기술의 도입은 건축, 기계, 전기 설비뿐만 아니라 운영 SLA(수질 관리 등)까지 새로운 기준을 요구합니다. 동시에 공랭 기술 또한 메모리, 스토리지 등 주변 장치를 위해 계속해서 고도화되어야 하는 하이브리드 냉각 시대가 도래했습니다.

이러한 변화의 시대에, 사용자가 직접 고가의 GPU를 구매하고, 빠르게 변화하는 기술을 따라잡으며, 복잡한 수랭 인프라를 직접 운영하는 것은 점점 더 비현실적이 되어가고 있습니다. 장비의 높은 가격, 빠른 노후화, 운영의 복잡성을 고려할 때, 가장 합리적인 선택은 필요한 만큼 빌려 쓰고 비용을 지불하는 **GPU-as-a-Service** 모델입니다.

NHN Cloud는 고밀도 데이터센터 운영 경험과 국가 AI 인프라 구축 프로젝트를 통해, 이러한 변화의 중심에 서 있습니다. 앞으로도 가장 효율적이고 안정적인 GPU 클라우드 서비스를 제공하며, 대한민국 AI 기술 발전의 핵심 기반을 다져나갈 것입니다.